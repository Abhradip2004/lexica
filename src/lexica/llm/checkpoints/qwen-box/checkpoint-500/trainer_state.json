{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002,
      "grad_norm": 4.611591339111328,
      "learning_rate": 0.0002,
      "loss": 2.8605,
      "step": 1
    },
    {
      "epoch": 0.004,
      "grad_norm": 1.1643939018249512,
      "learning_rate": 0.0001996,
      "loss": 2.6734,
      "step": 2
    },
    {
      "epoch": 0.006,
      "grad_norm": 1.1572322845458984,
      "learning_rate": 0.00019920000000000002,
      "loss": 2.6441,
      "step": 3
    },
    {
      "epoch": 0.008,
      "grad_norm": 1.0734018087387085,
      "learning_rate": 0.0001988,
      "loss": 2.5852,
      "step": 4
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8261936902999878,
      "learning_rate": 0.0001984,
      "loss": 2.5357,
      "step": 5
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.8521185517311096,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.481,
      "step": 6
    },
    {
      "epoch": 0.014,
      "grad_norm": 0.827669084072113,
      "learning_rate": 0.0001976,
      "loss": 2.401,
      "step": 7
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.8274936079978943,
      "learning_rate": 0.0001972,
      "loss": 2.3517,
      "step": 8
    },
    {
      "epoch": 0.018,
      "grad_norm": 0.840952455997467,
      "learning_rate": 0.0001968,
      "loss": 2.296,
      "step": 9
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9144784808158875,
      "learning_rate": 0.0001964,
      "loss": 2.2563,
      "step": 10
    },
    {
      "epoch": 0.022,
      "grad_norm": 0.951680600643158,
      "learning_rate": 0.000196,
      "loss": 2.1534,
      "step": 11
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.98297119140625,
      "learning_rate": 0.0001956,
      "loss": 2.1096,
      "step": 12
    },
    {
      "epoch": 0.026,
      "grad_norm": 1.073201298713684,
      "learning_rate": 0.0001952,
      "loss": 2.0265,
      "step": 13
    },
    {
      "epoch": 0.028,
      "grad_norm": 1.255973219871521,
      "learning_rate": 0.0001948,
      "loss": 1.9682,
      "step": 14
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.497408151626587,
      "learning_rate": 0.0001944,
      "loss": 1.8539,
      "step": 15
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.4768927097320557,
      "learning_rate": 0.000194,
      "loss": 1.7459,
      "step": 16
    },
    {
      "epoch": 0.034,
      "grad_norm": 3.4277710914611816,
      "learning_rate": 0.00019360000000000002,
      "loss": 1.6948,
      "step": 17
    },
    {
      "epoch": 0.036,
      "grad_norm": 4.9758219718933105,
      "learning_rate": 0.0001932,
      "loss": 1.659,
      "step": 18
    },
    {
      "epoch": 0.038,
      "grad_norm": 2.675877571105957,
      "learning_rate": 0.0001928,
      "loss": 1.5158,
      "step": 19
    },
    {
      "epoch": 0.04,
      "grad_norm": 3.058260202407837,
      "learning_rate": 0.00019240000000000001,
      "loss": 1.4561,
      "step": 20
    },
    {
      "epoch": 0.042,
      "grad_norm": 3.956796407699585,
      "learning_rate": 0.000192,
      "loss": 1.3832,
      "step": 21
    },
    {
      "epoch": 0.044,
      "grad_norm": 3.594935655593872,
      "learning_rate": 0.0001916,
      "loss": 1.2816,
      "step": 22
    },
    {
      "epoch": 0.046,
      "grad_norm": 2.5115482807159424,
      "learning_rate": 0.0001912,
      "loss": 1.2154,
      "step": 23
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.879418134689331,
      "learning_rate": 0.0001908,
      "loss": 1.1429,
      "step": 24
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.386486291885376,
      "learning_rate": 0.0001904,
      "loss": 1.0211,
      "step": 25
    },
    {
      "epoch": 0.052,
      "grad_norm": 2.495593309402466,
      "learning_rate": 0.00019,
      "loss": 0.9071,
      "step": 26
    },
    {
      "epoch": 0.054,
      "grad_norm": 2.0928494930267334,
      "learning_rate": 0.0001896,
      "loss": 0.818,
      "step": 27
    },
    {
      "epoch": 0.056,
      "grad_norm": 2.0834763050079346,
      "learning_rate": 0.0001892,
      "loss": 0.7097,
      "step": 28
    },
    {
      "epoch": 0.058,
      "grad_norm": 1.9197348356246948,
      "learning_rate": 0.0001888,
      "loss": 0.6573,
      "step": 29
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.8640506267547607,
      "learning_rate": 0.0001884,
      "loss": 0.5712,
      "step": 30
    },
    {
      "epoch": 0.062,
      "grad_norm": 1.8668103218078613,
      "learning_rate": 0.000188,
      "loss": 0.4697,
      "step": 31
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.7147120237350464,
      "learning_rate": 0.0001876,
      "loss": 0.3766,
      "step": 32
    },
    {
      "epoch": 0.066,
      "grad_norm": 1.4288809299468994,
      "learning_rate": 0.00018720000000000002,
      "loss": 0.3426,
      "step": 33
    },
    {
      "epoch": 0.068,
      "grad_norm": 1.3701106309890747,
      "learning_rate": 0.00018680000000000001,
      "loss": 0.2443,
      "step": 34
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.2172822952270508,
      "learning_rate": 0.00018640000000000003,
      "loss": 0.2149,
      "step": 35
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.132933259010315,
      "learning_rate": 0.00018600000000000002,
      "loss": 0.2236,
      "step": 36
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.7890987396240234,
      "learning_rate": 0.0001856,
      "loss": 0.1964,
      "step": 37
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.582578182220459,
      "learning_rate": 0.00018520000000000003,
      "loss": 0.1807,
      "step": 38
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.6183084845542908,
      "learning_rate": 0.00018480000000000002,
      "loss": 0.1696,
      "step": 39
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7861591577529907,
      "learning_rate": 0.0001844,
      "loss": 0.2006,
      "step": 40
    },
    {
      "epoch": 0.082,
      "grad_norm": 0.8808322548866272,
      "learning_rate": 0.00018400000000000003,
      "loss": 0.3353,
      "step": 41
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.47026824951171875,
      "learning_rate": 0.00018360000000000002,
      "loss": 0.1702,
      "step": 42
    },
    {
      "epoch": 0.086,
      "grad_norm": 0.31090620160102844,
      "learning_rate": 0.0001832,
      "loss": 0.1512,
      "step": 43
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.3956429660320282,
      "learning_rate": 0.00018280000000000003,
      "loss": 0.176,
      "step": 44
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.288183331489563,
      "learning_rate": 0.00018240000000000002,
      "loss": 0.1106,
      "step": 45
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.40650835633277893,
      "learning_rate": 0.000182,
      "loss": 0.1541,
      "step": 46
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.28380391001701355,
      "learning_rate": 0.00018160000000000002,
      "loss": 0.1335,
      "step": 47
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.26547971367836,
      "learning_rate": 0.0001812,
      "loss": 0.1328,
      "step": 48
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.33296579122543335,
      "learning_rate": 0.0001808,
      "loss": 0.1418,
      "step": 49
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2901666462421417,
      "learning_rate": 0.00018040000000000002,
      "loss": 0.1481,
      "step": 50
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.41586560010910034,
      "learning_rate": 0.00018,
      "loss": 0.1443,
      "step": 51
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.6200093030929565,
      "learning_rate": 0.0001796,
      "loss": 0.2741,
      "step": 52
    },
    {
      "epoch": 0.106,
      "grad_norm": 0.5636814832687378,
      "learning_rate": 0.00017920000000000002,
      "loss": 0.2671,
      "step": 53
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.3162033259868622,
      "learning_rate": 0.0001788,
      "loss": 0.0924,
      "step": 54
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8036976456642151,
      "learning_rate": 0.0001784,
      "loss": 0.1495,
      "step": 55
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.33916670083999634,
      "learning_rate": 0.00017800000000000002,
      "loss": 0.0928,
      "step": 56
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.32514646649360657,
      "learning_rate": 0.0001776,
      "loss": 0.0834,
      "step": 57
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.6534902453422546,
      "learning_rate": 0.0001772,
      "loss": 0.1506,
      "step": 58
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.30431684851646423,
      "learning_rate": 0.00017680000000000001,
      "loss": 0.1206,
      "step": 59
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.326557993888855,
      "learning_rate": 0.0001764,
      "loss": 0.1243,
      "step": 60
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.6828104257583618,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.2407,
      "step": 61
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.3004542589187622,
      "learning_rate": 0.0001756,
      "loss": 0.1026,
      "step": 62
    },
    {
      "epoch": 0.126,
      "grad_norm": 0.37832218408584595,
      "learning_rate": 0.0001752,
      "loss": 0.1226,
      "step": 63
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.6520500183105469,
      "learning_rate": 0.00017480000000000002,
      "loss": 0.1147,
      "step": 64
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.4226248264312744,
      "learning_rate": 0.0001744,
      "loss": 0.1459,
      "step": 65
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.2667287588119507,
      "learning_rate": 0.000174,
      "loss": 0.1029,
      "step": 66
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.3101501762866974,
      "learning_rate": 0.00017360000000000002,
      "loss": 0.117,
      "step": 67
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.2676945924758911,
      "learning_rate": 0.0001732,
      "loss": 0.11,
      "step": 68
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.42664653062820435,
      "learning_rate": 0.0001728,
      "loss": 0.1252,
      "step": 69
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.2949058413505554,
      "learning_rate": 0.00017240000000000002,
      "loss": 0.119,
      "step": 70
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.45345500111579895,
      "learning_rate": 0.000172,
      "loss": 0.2109,
      "step": 71
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.5194278359413147,
      "learning_rate": 0.0001716,
      "loss": 0.132,
      "step": 72
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.5147703289985657,
      "learning_rate": 0.00017120000000000001,
      "loss": 0.2018,
      "step": 73
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.5121389627456665,
      "learning_rate": 0.0001708,
      "loss": 0.1139,
      "step": 74
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.2958180606365204,
      "learning_rate": 0.0001704,
      "loss": 0.0814,
      "step": 75
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.9764143228530884,
      "learning_rate": 0.00017,
      "loss": 0.1023,
      "step": 76
    },
    {
      "epoch": 0.154,
      "grad_norm": 0.44008970260620117,
      "learning_rate": 0.0001696,
      "loss": 0.1069,
      "step": 77
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.49902909994125366,
      "learning_rate": 0.0001692,
      "loss": 0.0693,
      "step": 78
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.7077954411506653,
      "learning_rate": 0.0001688,
      "loss": 0.0849,
      "step": 79
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.6364057064056396,
      "learning_rate": 0.0001684,
      "loss": 0.1816,
      "step": 80
    },
    {
      "epoch": 0.162,
      "grad_norm": 1.0288764238357544,
      "learning_rate": 0.000168,
      "loss": 0.1043,
      "step": 81
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.3934536278247833,
      "learning_rate": 0.0001676,
      "loss": 0.0902,
      "step": 82
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.3300870358943939,
      "learning_rate": 0.0001672,
      "loss": 0.0796,
      "step": 83
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.4001644253730774,
      "learning_rate": 0.0001668,
      "loss": 0.0854,
      "step": 84
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.5507493019104004,
      "learning_rate": 0.0001664,
      "loss": 0.09,
      "step": 85
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.34677398204803467,
      "learning_rate": 0.000166,
      "loss": 0.1262,
      "step": 86
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.44823822379112244,
      "learning_rate": 0.0001656,
      "loss": 0.0695,
      "step": 87
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.38548240065574646,
      "learning_rate": 0.0001652,
      "loss": 0.076,
      "step": 88
    },
    {
      "epoch": 0.178,
      "grad_norm": 0.5426198840141296,
      "learning_rate": 0.0001648,
      "loss": 0.0836,
      "step": 89
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.4087238609790802,
      "learning_rate": 0.0001644,
      "loss": 0.097,
      "step": 90
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.4254336655139923,
      "learning_rate": 0.000164,
      "loss": 0.0744,
      "step": 91
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.3513137102127075,
      "learning_rate": 0.0001636,
      "loss": 0.0667,
      "step": 92
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.4121488332748413,
      "learning_rate": 0.0001632,
      "loss": 0.0862,
      "step": 93
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.3725043535232544,
      "learning_rate": 0.0001628,
      "loss": 0.0534,
      "step": 94
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9841805100440979,
      "learning_rate": 0.00016240000000000002,
      "loss": 0.1645,
      "step": 95
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.4411170184612274,
      "learning_rate": 0.000162,
      "loss": 0.0876,
      "step": 96
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.4850752055644989,
      "learning_rate": 0.00016160000000000002,
      "loss": 0.0479,
      "step": 97
    },
    {
      "epoch": 0.196,
      "grad_norm": 1.1584678888320923,
      "learning_rate": 0.00016120000000000002,
      "loss": 0.1127,
      "step": 98
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.7629992365837097,
      "learning_rate": 0.0001608,
      "loss": 0.0677,
      "step": 99
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2520418167114258,
      "learning_rate": 0.00016040000000000002,
      "loss": 0.1166,
      "step": 100
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.6901283264160156,
      "learning_rate": 0.00016,
      "loss": 0.1055,
      "step": 101
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.3061577379703522,
      "learning_rate": 0.0001596,
      "loss": 0.0502,
      "step": 102
    },
    {
      "epoch": 0.206,
      "grad_norm": 0.31243205070495605,
      "learning_rate": 0.00015920000000000002,
      "loss": 0.0455,
      "step": 103
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.7425776720046997,
      "learning_rate": 0.0001588,
      "loss": 0.0586,
      "step": 104
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.5293942093849182,
      "learning_rate": 0.00015840000000000003,
      "loss": 0.0655,
      "step": 105
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.8613719344139099,
      "learning_rate": 0.00015800000000000002,
      "loss": 0.1519,
      "step": 106
    },
    {
      "epoch": 0.214,
      "grad_norm": 0.4572772681713104,
      "learning_rate": 0.0001576,
      "loss": 0.1126,
      "step": 107
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.5113027691841125,
      "learning_rate": 0.00015720000000000003,
      "loss": 0.058,
      "step": 108
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.2854548990726471,
      "learning_rate": 0.00015680000000000002,
      "loss": 0.0476,
      "step": 109
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3970169425010681,
      "learning_rate": 0.0001564,
      "loss": 0.0435,
      "step": 110
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.3973982036113739,
      "learning_rate": 0.00015600000000000002,
      "loss": 0.0738,
      "step": 111
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3441334068775177,
      "learning_rate": 0.00015560000000000001,
      "loss": 0.043,
      "step": 112
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.8493152856826782,
      "learning_rate": 0.0001552,
      "loss": 0.0802,
      "step": 113
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.48327863216400146,
      "learning_rate": 0.00015480000000000002,
      "loss": 0.0708,
      "step": 114
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.5151220560073853,
      "learning_rate": 0.0001544,
      "loss": 0.0807,
      "step": 115
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.5648048520088196,
      "learning_rate": 0.000154,
      "loss": 0.0955,
      "step": 116
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.6550105810165405,
      "learning_rate": 0.00015360000000000002,
      "loss": 0.0578,
      "step": 117
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.41227343678474426,
      "learning_rate": 0.0001532,
      "loss": 0.0653,
      "step": 118
    },
    {
      "epoch": 0.238,
      "grad_norm": 1.0588687658309937,
      "learning_rate": 0.0001528,
      "loss": 0.1002,
      "step": 119
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.42176365852355957,
      "learning_rate": 0.00015240000000000002,
      "loss": 0.049,
      "step": 120
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.5330672860145569,
      "learning_rate": 0.000152,
      "loss": 0.0666,
      "step": 121
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.5675261616706848,
      "learning_rate": 0.0001516,
      "loss": 0.0329,
      "step": 122
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.3679068088531494,
      "learning_rate": 0.00015120000000000002,
      "loss": 0.0347,
      "step": 123
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.3120066821575165,
      "learning_rate": 0.0001508,
      "loss": 0.0319,
      "step": 124
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9525130987167358,
      "learning_rate": 0.0001504,
      "loss": 0.0824,
      "step": 125
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.45856449007987976,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.0342,
      "step": 126
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.3714679777622223,
      "learning_rate": 0.0001496,
      "loss": 0.0778,
      "step": 127
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.3009377121925354,
      "learning_rate": 0.0001492,
      "loss": 0.0308,
      "step": 128
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.6940158605575562,
      "learning_rate": 0.0001488,
      "loss": 0.1154,
      "step": 129
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.49809372425079346,
      "learning_rate": 0.0001484,
      "loss": 0.078,
      "step": 130
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.281332790851593,
      "learning_rate": 0.000148,
      "loss": 0.0294,
      "step": 131
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.4667600095272064,
      "learning_rate": 0.0001476,
      "loss": 0.0527,
      "step": 132
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.42031943798065186,
      "learning_rate": 0.0001472,
      "loss": 0.0794,
      "step": 133
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.3579862415790558,
      "learning_rate": 0.00014680000000000002,
      "loss": 0.0335,
      "step": 134
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.3815802335739136,
      "learning_rate": 0.0001464,
      "loss": 0.0293,
      "step": 135
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.43350228667259216,
      "learning_rate": 0.000146,
      "loss": 0.0643,
      "step": 136
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.406904011964798,
      "learning_rate": 0.00014560000000000002,
      "loss": 0.068,
      "step": 137
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.5515012145042419,
      "learning_rate": 0.0001452,
      "loss": 0.0605,
      "step": 138
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.7187666893005371,
      "learning_rate": 0.0001448,
      "loss": 0.03,
      "step": 139
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6222442388534546,
      "learning_rate": 0.0001444,
      "loss": 0.0545,
      "step": 140
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.37312552332878113,
      "learning_rate": 0.000144,
      "loss": 0.0495,
      "step": 141
    },
    {
      "epoch": 0.284,
      "grad_norm": 1.4037206172943115,
      "learning_rate": 0.0001436,
      "loss": 0.0304,
      "step": 142
    },
    {
      "epoch": 0.286,
      "grad_norm": 1.7734060287475586,
      "learning_rate": 0.0001432,
      "loss": 0.0374,
      "step": 143
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.4794333875179291,
      "learning_rate": 0.0001428,
      "loss": 0.05,
      "step": 144
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.5641050338745117,
      "learning_rate": 0.0001424,
      "loss": 0.0474,
      "step": 145
    },
    {
      "epoch": 0.292,
      "grad_norm": 1.6302895545959473,
      "learning_rate": 0.000142,
      "loss": 0.1194,
      "step": 146
    },
    {
      "epoch": 0.294,
      "grad_norm": 1.740503191947937,
      "learning_rate": 0.0001416,
      "loss": 0.0786,
      "step": 147
    },
    {
      "epoch": 0.296,
      "grad_norm": 1.1394879817962646,
      "learning_rate": 0.0001412,
      "loss": 0.0687,
      "step": 148
    },
    {
      "epoch": 0.298,
      "grad_norm": 1.215262532234192,
      "learning_rate": 0.0001408,
      "loss": 0.0756,
      "step": 149
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.39595916867256165,
      "learning_rate": 0.0001404,
      "loss": 0.0307,
      "step": 150
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.36468377709388733,
      "learning_rate": 0.00014,
      "loss": 0.054,
      "step": 151
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.4646182060241699,
      "learning_rate": 0.0001396,
      "loss": 0.0325,
      "step": 152
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.3605038523674011,
      "learning_rate": 0.0001392,
      "loss": 0.0653,
      "step": 153
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.3514162003993988,
      "learning_rate": 0.00013879999999999999,
      "loss": 0.0673,
      "step": 154
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.3295452296733856,
      "learning_rate": 0.0001384,
      "loss": 0.0624,
      "step": 155
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.29547542333602905,
      "learning_rate": 0.000138,
      "loss": 0.0673,
      "step": 156
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.2379060536623001,
      "learning_rate": 0.00013759999999999998,
      "loss": 0.0771,
      "step": 157
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.6524715423583984,
      "learning_rate": 0.00013720000000000003,
      "loss": 0.106,
      "step": 158
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.2912437915802002,
      "learning_rate": 0.00013680000000000002,
      "loss": 0.038,
      "step": 159
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.27075785398483276,
      "learning_rate": 0.0001364,
      "loss": 0.0665,
      "step": 160
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.24111895263195038,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.0783,
      "step": 161
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.43807217478752136,
      "learning_rate": 0.00013560000000000002,
      "loss": 0.0268,
      "step": 162
    },
    {
      "epoch": 0.326,
      "grad_norm": 0.3206093907356262,
      "learning_rate": 0.0001352,
      "loss": 0.0602,
      "step": 163
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.21882542967796326,
      "learning_rate": 0.00013480000000000002,
      "loss": 0.0268,
      "step": 164
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.3863023817539215,
      "learning_rate": 0.00013440000000000001,
      "loss": 0.0329,
      "step": 165
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.5260666608810425,
      "learning_rate": 0.000134,
      "loss": 0.1122,
      "step": 166
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.47080886363983154,
      "learning_rate": 0.00013360000000000002,
      "loss": 0.0447,
      "step": 167
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.28479135036468506,
      "learning_rate": 0.0001332,
      "loss": 0.0648,
      "step": 168
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.3929513990879059,
      "learning_rate": 0.0001328,
      "loss": 0.0332,
      "step": 169
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.3045366704463959,
      "learning_rate": 0.00013240000000000002,
      "loss": 0.0302,
      "step": 170
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.47628480195999146,
      "learning_rate": 0.000132,
      "loss": 0.0576,
      "step": 171
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.7033989429473877,
      "learning_rate": 0.0001316,
      "loss": 0.0818,
      "step": 172
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.29108771681785583,
      "learning_rate": 0.00013120000000000002,
      "loss": 0.0709,
      "step": 173
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.3664996325969696,
      "learning_rate": 0.0001308,
      "loss": 0.0653,
      "step": 174
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.30643966794013977,
      "learning_rate": 0.0001304,
      "loss": 0.0157,
      "step": 175
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.5321829915046692,
      "learning_rate": 0.00013000000000000002,
      "loss": 0.0688,
      "step": 176
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.4467785656452179,
      "learning_rate": 0.0001296,
      "loss": 0.0526,
      "step": 177
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.6888787150382996,
      "learning_rate": 0.00012920000000000002,
      "loss": 0.0544,
      "step": 178
    },
    {
      "epoch": 0.358,
      "grad_norm": 0.3450603485107422,
      "learning_rate": 0.00012880000000000001,
      "loss": 0.0592,
      "step": 179
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.41484561562538147,
      "learning_rate": 0.0001284,
      "loss": 0.0818,
      "step": 180
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.32013216614723206,
      "learning_rate": 0.00012800000000000002,
      "loss": 0.0535,
      "step": 181
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.29681697487831116,
      "learning_rate": 0.0001276,
      "loss": 0.0206,
      "step": 182
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.8594393730163574,
      "learning_rate": 0.0001272,
      "loss": 0.078,
      "step": 183
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.6506185531616211,
      "learning_rate": 0.00012680000000000002,
      "loss": 0.0389,
      "step": 184
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.6642950773239136,
      "learning_rate": 0.0001264,
      "loss": 0.093,
      "step": 185
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.23267342150211334,
      "learning_rate": 0.000126,
      "loss": 0.0427,
      "step": 186
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.4530221223831177,
      "learning_rate": 0.00012560000000000002,
      "loss": 0.0659,
      "step": 187
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.4973175525665283,
      "learning_rate": 0.0001252,
      "loss": 0.0689,
      "step": 188
    },
    {
      "epoch": 0.378,
      "grad_norm": 1.134193778038025,
      "learning_rate": 0.0001248,
      "loss": 0.0408,
      "step": 189
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.6251989603042603,
      "learning_rate": 0.00012440000000000002,
      "loss": 0.0893,
      "step": 190
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.2780660092830658,
      "learning_rate": 0.000124,
      "loss": 0.0262,
      "step": 191
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.3798573911190033,
      "learning_rate": 0.0001236,
      "loss": 0.027,
      "step": 192
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.39596372842788696,
      "learning_rate": 0.0001232,
      "loss": 0.064,
      "step": 193
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.6533653140068054,
      "learning_rate": 0.0001228,
      "loss": 0.0627,
      "step": 194
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.7671256065368652,
      "learning_rate": 0.0001224,
      "loss": 0.0395,
      "step": 195
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.29632270336151123,
      "learning_rate": 0.000122,
      "loss": 0.0285,
      "step": 196
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.3564412295818329,
      "learning_rate": 0.0001216,
      "loss": 0.0583,
      "step": 197
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.2630311846733093,
      "learning_rate": 0.0001212,
      "loss": 0.0262,
      "step": 198
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.31438687443733215,
      "learning_rate": 0.0001208,
      "loss": 0.0581,
      "step": 199
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5534877777099609,
      "learning_rate": 0.0001204,
      "loss": 0.0599,
      "step": 200
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.6624106168746948,
      "learning_rate": 0.00012,
      "loss": 0.0738,
      "step": 201
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.28832367062568665,
      "learning_rate": 0.00011960000000000001,
      "loss": 0.0262,
      "step": 202
    },
    {
      "epoch": 0.406,
      "grad_norm": 1.1675770282745361,
      "learning_rate": 0.0001192,
      "loss": 0.0871,
      "step": 203
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.9845072031021118,
      "learning_rate": 0.0001188,
      "loss": 0.0361,
      "step": 204
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.2605765461921692,
      "learning_rate": 0.0001184,
      "loss": 0.0568,
      "step": 205
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.22211767733097076,
      "learning_rate": 0.000118,
      "loss": 0.0241,
      "step": 206
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.5999126434326172,
      "learning_rate": 0.0001176,
      "loss": 0.0772,
      "step": 207
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.25089678168296814,
      "learning_rate": 0.0001172,
      "loss": 0.0272,
      "step": 208
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.6001781821250916,
      "learning_rate": 0.00011679999999999999,
      "loss": 0.0737,
      "step": 209
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.2602907121181488,
      "learning_rate": 0.0001164,
      "loss": 0.052,
      "step": 210
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.2825123369693756,
      "learning_rate": 0.000116,
      "loss": 0.0515,
      "step": 211
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.5856831073760986,
      "learning_rate": 0.00011559999999999999,
      "loss": 0.0584,
      "step": 212
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.5005454421043396,
      "learning_rate": 0.0001152,
      "loss": 0.038,
      "step": 213
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.28984421491622925,
      "learning_rate": 0.0001148,
      "loss": 0.0524,
      "step": 214
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.3632113039493561,
      "learning_rate": 0.0001144,
      "loss": 0.0274,
      "step": 215
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.33696720004081726,
      "learning_rate": 0.00011399999999999999,
      "loss": 0.056,
      "step": 216
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.7029829621315002,
      "learning_rate": 0.0001136,
      "loss": 0.0627,
      "step": 217
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.36950403451919556,
      "learning_rate": 0.0001132,
      "loss": 0.0526,
      "step": 218
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.4591538906097412,
      "learning_rate": 0.00011279999999999999,
      "loss": 0.0557,
      "step": 219
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3970455527305603,
      "learning_rate": 0.00011240000000000002,
      "loss": 0.027,
      "step": 220
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.5211454629898071,
      "learning_rate": 0.00011200000000000001,
      "loss": 0.0292,
      "step": 221
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.3983932137489319,
      "learning_rate": 0.00011160000000000002,
      "loss": 0.0258,
      "step": 222
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.4301075041294098,
      "learning_rate": 0.00011120000000000002,
      "loss": 0.0582,
      "step": 223
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.347720205783844,
      "learning_rate": 0.00011080000000000001,
      "loss": 0.055,
      "step": 224
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.791545569896698,
      "learning_rate": 0.00011040000000000001,
      "loss": 0.0716,
      "step": 225
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.3275214731693268,
      "learning_rate": 0.00011000000000000002,
      "loss": 0.0255,
      "step": 226
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.3164913058280945,
      "learning_rate": 0.00010960000000000001,
      "loss": 0.0286,
      "step": 227
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.4331498146057129,
      "learning_rate": 0.00010920000000000001,
      "loss": 0.0671,
      "step": 228
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.29669249057769775,
      "learning_rate": 0.00010880000000000002,
      "loss": 0.0512,
      "step": 229
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.441760778427124,
      "learning_rate": 0.00010840000000000002,
      "loss": 0.0276,
      "step": 230
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.28285253047943115,
      "learning_rate": 0.00010800000000000001,
      "loss": 0.0206,
      "step": 231
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.345497727394104,
      "learning_rate": 0.00010760000000000001,
      "loss": 0.0585,
      "step": 232
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.23221422731876373,
      "learning_rate": 0.00010720000000000002,
      "loss": 0.0228,
      "step": 233
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.31752899289131165,
      "learning_rate": 0.00010680000000000001,
      "loss": 0.0579,
      "step": 234
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.27121293544769287,
      "learning_rate": 0.00010640000000000001,
      "loss": 0.0238,
      "step": 235
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.33975058794021606,
      "learning_rate": 0.00010600000000000002,
      "loss": 0.0308,
      "step": 236
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.9967586994171143,
      "learning_rate": 0.0001056,
      "loss": 0.0387,
      "step": 237
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.3489519953727722,
      "learning_rate": 0.00010520000000000001,
      "loss": 0.063,
      "step": 238
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.6212018728256226,
      "learning_rate": 0.00010480000000000001,
      "loss": 0.0695,
      "step": 239
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.26616767048835754,
      "learning_rate": 0.0001044,
      "loss": 0.057,
      "step": 240
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.5105432271957397,
      "learning_rate": 0.00010400000000000001,
      "loss": 0.0636,
      "step": 241
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.45631974935531616,
      "learning_rate": 0.00010360000000000001,
      "loss": 0.0673,
      "step": 242
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.19694072008132935,
      "learning_rate": 0.0001032,
      "loss": 0.0223,
      "step": 243
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.32380411028862,
      "learning_rate": 0.0001028,
      "loss": 0.03,
      "step": 244
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.19642585515975952,
      "learning_rate": 0.00010240000000000001,
      "loss": 0.0228,
      "step": 245
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.23618093132972717,
      "learning_rate": 0.00010200000000000001,
      "loss": 0.0214,
      "step": 246
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.27838826179504395,
      "learning_rate": 0.0001016,
      "loss": 0.0295,
      "step": 247
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.26133349537849426,
      "learning_rate": 0.00010120000000000001,
      "loss": 0.0539,
      "step": 248
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.32242098450660706,
      "learning_rate": 0.00010080000000000001,
      "loss": 0.0647,
      "step": 249
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.37963056564331055,
      "learning_rate": 0.0001004,
      "loss": 0.0598,
      "step": 250
    },
    {
      "epoch": 0.502,
      "grad_norm": 0.32191014289855957,
      "learning_rate": 0.0001,
      "loss": 0.0594,
      "step": 251
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.3040870130062103,
      "learning_rate": 9.960000000000001e-05,
      "loss": 0.0587,
      "step": 252
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.3035317063331604,
      "learning_rate": 9.92e-05,
      "loss": 0.0543,
      "step": 253
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.5345295667648315,
      "learning_rate": 9.88e-05,
      "loss": 0.0599,
      "step": 254
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.3704613447189331,
      "learning_rate": 9.84e-05,
      "loss": 0.0323,
      "step": 255
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.40932825207710266,
      "learning_rate": 9.8e-05,
      "loss": 0.0495,
      "step": 256
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.3377057611942291,
      "learning_rate": 9.76e-05,
      "loss": 0.0506,
      "step": 257
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.3095191717147827,
      "learning_rate": 9.72e-05,
      "loss": 0.0262,
      "step": 258
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.28165823221206665,
      "learning_rate": 9.680000000000001e-05,
      "loss": 0.0537,
      "step": 259
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.28033602237701416,
      "learning_rate": 9.64e-05,
      "loss": 0.0254,
      "step": 260
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.28104454278945923,
      "learning_rate": 9.6e-05,
      "loss": 0.027,
      "step": 261
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.3735761344432831,
      "learning_rate": 9.56e-05,
      "loss": 0.0269,
      "step": 262
    },
    {
      "epoch": 0.526,
      "grad_norm": 0.6280301213264465,
      "learning_rate": 9.52e-05,
      "loss": 0.0585,
      "step": 263
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.29404833912849426,
      "learning_rate": 9.48e-05,
      "loss": 0.026,
      "step": 264
    },
    {
      "epoch": 0.53,
      "grad_norm": 1.5758099555969238,
      "learning_rate": 9.44e-05,
      "loss": 0.0955,
      "step": 265
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.2838689982891083,
      "learning_rate": 9.4e-05,
      "loss": 0.0535,
      "step": 266
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.27572986483573914,
      "learning_rate": 9.360000000000001e-05,
      "loss": 0.0236,
      "step": 267
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.3222171366214752,
      "learning_rate": 9.320000000000002e-05,
      "loss": 0.0568,
      "step": 268
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.3078451454639435,
      "learning_rate": 9.28e-05,
      "loss": 0.055,
      "step": 269
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.597613513469696,
      "learning_rate": 9.240000000000001e-05,
      "loss": 0.0641,
      "step": 270
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.2013271450996399,
      "learning_rate": 9.200000000000001e-05,
      "loss": 0.0227,
      "step": 271
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.7083525657653809,
      "learning_rate": 9.16e-05,
      "loss": 0.073,
      "step": 272
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.45980310440063477,
      "learning_rate": 9.120000000000001e-05,
      "loss": 0.0529,
      "step": 273
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.19665658473968506,
      "learning_rate": 9.080000000000001e-05,
      "loss": 0.0236,
      "step": 274
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.2193320244550705,
      "learning_rate": 9.04e-05,
      "loss": 0.0219,
      "step": 275
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.26508963108062744,
      "learning_rate": 9e-05,
      "loss": 0.0246,
      "step": 276
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.37880179286003113,
      "learning_rate": 8.960000000000001e-05,
      "loss": 0.0276,
      "step": 277
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.33970415592193604,
      "learning_rate": 8.92e-05,
      "loss": 0.0269,
      "step": 278
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.2065620720386505,
      "learning_rate": 8.88e-05,
      "loss": 0.0249,
      "step": 279
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.4559781849384308,
      "learning_rate": 8.840000000000001e-05,
      "loss": 0.0316,
      "step": 280
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.20573319494724274,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.0533,
      "step": 281
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.3523310720920563,
      "learning_rate": 8.76e-05,
      "loss": 0.0555,
      "step": 282
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.3536052405834198,
      "learning_rate": 8.72e-05,
      "loss": 0.0549,
      "step": 283
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.34674346446990967,
      "learning_rate": 8.680000000000001e-05,
      "loss": 0.0539,
      "step": 284
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.23306496441364288,
      "learning_rate": 8.64e-05,
      "loss": 0.0549,
      "step": 285
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.2403508424758911,
      "learning_rate": 8.6e-05,
      "loss": 0.0588,
      "step": 286
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.8773440718650818,
      "learning_rate": 8.560000000000001e-05,
      "loss": 0.0689,
      "step": 287
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.2765809893608093,
      "learning_rate": 8.52e-05,
      "loss": 0.0222,
      "step": 288
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.26772060990333557,
      "learning_rate": 8.48e-05,
      "loss": 0.0501,
      "step": 289
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.6043065190315247,
      "learning_rate": 8.44e-05,
      "loss": 0.0645,
      "step": 290
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.2001129686832428,
      "learning_rate": 8.4e-05,
      "loss": 0.0248,
      "step": 291
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.4058060348033905,
      "learning_rate": 8.36e-05,
      "loss": 0.0569,
      "step": 292
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.2921101450920105,
      "learning_rate": 8.32e-05,
      "loss": 0.0549,
      "step": 293
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.30165812373161316,
      "learning_rate": 8.28e-05,
      "loss": 0.0227,
      "step": 294
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.328738808631897,
      "learning_rate": 8.24e-05,
      "loss": 0.0284,
      "step": 295
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.24216994643211365,
      "learning_rate": 8.2e-05,
      "loss": 0.0216,
      "step": 296
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.33656907081604004,
      "learning_rate": 8.16e-05,
      "loss": 0.061,
      "step": 297
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.2434680461883545,
      "learning_rate": 8.120000000000001e-05,
      "loss": 0.0506,
      "step": 298
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.19159702956676483,
      "learning_rate": 8.080000000000001e-05,
      "loss": 0.0238,
      "step": 299
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.22002294659614563,
      "learning_rate": 8.04e-05,
      "loss": 0.0525,
      "step": 300
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.22732259333133698,
      "learning_rate": 8e-05,
      "loss": 0.0259,
      "step": 301
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.2553468346595764,
      "learning_rate": 7.960000000000001e-05,
      "loss": 0.0248,
      "step": 302
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.2737918496131897,
      "learning_rate": 7.920000000000001e-05,
      "loss": 0.028,
      "step": 303
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.2734083831310272,
      "learning_rate": 7.88e-05,
      "loss": 0.0536,
      "step": 304
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.4846220910549164,
      "learning_rate": 7.840000000000001e-05,
      "loss": 0.0615,
      "step": 305
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.2784901559352875,
      "learning_rate": 7.800000000000001e-05,
      "loss": 0.057,
      "step": 306
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.3485560417175293,
      "learning_rate": 7.76e-05,
      "loss": 0.0581,
      "step": 307
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.5115767121315002,
      "learning_rate": 7.72e-05,
      "loss": 0.0614,
      "step": 308
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.36981943249702454,
      "learning_rate": 7.680000000000001e-05,
      "loss": 0.0562,
      "step": 309
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.1917765587568283,
      "learning_rate": 7.64e-05,
      "loss": 0.0242,
      "step": 310
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.38179877400398254,
      "learning_rate": 7.6e-05,
      "loss": 0.063,
      "step": 311
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.3090395927429199,
      "learning_rate": 7.560000000000001e-05,
      "loss": 0.0582,
      "step": 312
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.2497200220823288,
      "learning_rate": 7.52e-05,
      "loss": 0.0572,
      "step": 313
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.32506129145622253,
      "learning_rate": 7.48e-05,
      "loss": 0.0281,
      "step": 314
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.22920085489749908,
      "learning_rate": 7.44e-05,
      "loss": 0.0537,
      "step": 315
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.3093715310096741,
      "learning_rate": 7.4e-05,
      "loss": 0.057,
      "step": 316
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.28623688220977783,
      "learning_rate": 7.36e-05,
      "loss": 0.0546,
      "step": 317
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.26979130506515503,
      "learning_rate": 7.32e-05,
      "loss": 0.0502,
      "step": 318
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.1917770504951477,
      "learning_rate": 7.280000000000001e-05,
      "loss": 0.0539,
      "step": 319
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.21223753690719604,
      "learning_rate": 7.24e-05,
      "loss": 0.0529,
      "step": 320
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.3349163830280304,
      "learning_rate": 7.2e-05,
      "loss": 0.0509,
      "step": 321
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.49508339166641235,
      "learning_rate": 7.16e-05,
      "loss": 0.0665,
      "step": 322
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.3253006041049957,
      "learning_rate": 7.12e-05,
      "loss": 0.0238,
      "step": 323
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.3310113847255707,
      "learning_rate": 7.08e-05,
      "loss": 0.0263,
      "step": 324
    },
    {
      "epoch": 0.65,
      "grad_norm": 1.1416757106781006,
      "learning_rate": 7.04e-05,
      "loss": 0.0746,
      "step": 325
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.312496542930603,
      "learning_rate": 7e-05,
      "loss": 0.0265,
      "step": 326
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.22462309896945953,
      "learning_rate": 6.96e-05,
      "loss": 0.0535,
      "step": 327
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.23305127024650574,
      "learning_rate": 6.92e-05,
      "loss": 0.0516,
      "step": 328
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.1916101574897766,
      "learning_rate": 6.879999999999999e-05,
      "loss": 0.0501,
      "step": 329
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.28048211336135864,
      "learning_rate": 6.840000000000001e-05,
      "loss": 0.0533,
      "step": 330
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.2299334704875946,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.052,
      "step": 331
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.6424692869186401,
      "learning_rate": 6.76e-05,
      "loss": 0.0311,
      "step": 332
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.23843519389629364,
      "learning_rate": 6.720000000000001e-05,
      "loss": 0.0261,
      "step": 333
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.24269519746303558,
      "learning_rate": 6.680000000000001e-05,
      "loss": 0.0254,
      "step": 334
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.3722955882549286,
      "learning_rate": 6.64e-05,
      "loss": 0.0249,
      "step": 335
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.23978953063488007,
      "learning_rate": 6.6e-05,
      "loss": 0.0534,
      "step": 336
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.21336357295513153,
      "learning_rate": 6.560000000000001e-05,
      "loss": 0.0244,
      "step": 337
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.2163521945476532,
      "learning_rate": 6.52e-05,
      "loss": 0.0224,
      "step": 338
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.2532270848751068,
      "learning_rate": 6.48e-05,
      "loss": 0.0526,
      "step": 339
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.41176965832710266,
      "learning_rate": 6.440000000000001e-05,
      "loss": 0.0247,
      "step": 340
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.360868901014328,
      "learning_rate": 6.400000000000001e-05,
      "loss": 0.0579,
      "step": 341
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.24197803437709808,
      "learning_rate": 6.36e-05,
      "loss": 0.0238,
      "step": 342
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.22912108898162842,
      "learning_rate": 6.32e-05,
      "loss": 0.0229,
      "step": 343
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.22066517174243927,
      "learning_rate": 6.280000000000001e-05,
      "loss": 0.0219,
      "step": 344
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.3589975833892822,
      "learning_rate": 6.24e-05,
      "loss": 0.0554,
      "step": 345
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.3355424702167511,
      "learning_rate": 6.2e-05,
      "loss": 0.025,
      "step": 346
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.20791257917881012,
      "learning_rate": 6.16e-05,
      "loss": 0.0248,
      "step": 347
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.27482011914253235,
      "learning_rate": 6.12e-05,
      "loss": 0.0517,
      "step": 348
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.33467113971710205,
      "learning_rate": 6.08e-05,
      "loss": 0.0303,
      "step": 349
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.29974564909935,
      "learning_rate": 6.04e-05,
      "loss": 0.0605,
      "step": 350
    },
    {
      "epoch": 0.702,
      "grad_norm": 0.24596090614795685,
      "learning_rate": 6e-05,
      "loss": 0.0516,
      "step": 351
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.2024552822113037,
      "learning_rate": 5.96e-05,
      "loss": 0.0499,
      "step": 352
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.35035473108291626,
      "learning_rate": 5.92e-05,
      "loss": 0.0555,
      "step": 353
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.282413512468338,
      "learning_rate": 5.88e-05,
      "loss": 0.0554,
      "step": 354
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.2946803867816925,
      "learning_rate": 5.8399999999999997e-05,
      "loss": 0.0288,
      "step": 355
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.3279934525489807,
      "learning_rate": 5.8e-05,
      "loss": 0.0295,
      "step": 356
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.3259613811969757,
      "learning_rate": 5.76e-05,
      "loss": 0.0526,
      "step": 357
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.2715001404285431,
      "learning_rate": 5.72e-05,
      "loss": 0.0528,
      "step": 358
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.5929808616638184,
      "learning_rate": 5.68e-05,
      "loss": 0.023,
      "step": 359
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.2503804862499237,
      "learning_rate": 5.6399999999999995e-05,
      "loss": 0.0223,
      "step": 360
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.2557646334171295,
      "learning_rate": 5.6000000000000006e-05,
      "loss": 0.0462,
      "step": 361
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.2158934324979782,
      "learning_rate": 5.560000000000001e-05,
      "loss": 0.0531,
      "step": 362
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.4739248752593994,
      "learning_rate": 5.520000000000001e-05,
      "loss": 0.0237,
      "step": 363
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.2317999303340912,
      "learning_rate": 5.4800000000000004e-05,
      "loss": 0.0205,
      "step": 364
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.2623860836029053,
      "learning_rate": 5.440000000000001e-05,
      "loss": 0.054,
      "step": 365
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.3754357695579529,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 0.0579,
      "step": 366
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.21157771348953247,
      "learning_rate": 5.360000000000001e-05,
      "loss": 0.051,
      "step": 367
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.32861772179603577,
      "learning_rate": 5.3200000000000006e-05,
      "loss": 0.0189,
      "step": 368
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.25900447368621826,
      "learning_rate": 5.28e-05,
      "loss": 0.0266,
      "step": 369
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.5792391300201416,
      "learning_rate": 5.2400000000000007e-05,
      "loss": 0.0624,
      "step": 370
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.22044837474822998,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 0.0516,
      "step": 371
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.38904330134391785,
      "learning_rate": 5.16e-05,
      "loss": 0.0279,
      "step": 372
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.37760233879089355,
      "learning_rate": 5.1200000000000004e-05,
      "loss": 0.0522,
      "step": 373
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.29241424798965454,
      "learning_rate": 5.08e-05,
      "loss": 0.0237,
      "step": 374
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.32632574439048767,
      "learning_rate": 5.0400000000000005e-05,
      "loss": 0.0638,
      "step": 375
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.28975343704223633,
      "learning_rate": 5e-05,
      "loss": 0.0585,
      "step": 376
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.29698145389556885,
      "learning_rate": 4.96e-05,
      "loss": 0.0534,
      "step": 377
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.2956787347793579,
      "learning_rate": 4.92e-05,
      "loss": 0.0571,
      "step": 378
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.26889917254447937,
      "learning_rate": 4.88e-05,
      "loss": 0.0226,
      "step": 379
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4607331156730652,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.0259,
      "step": 380
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.23335593938827515,
      "learning_rate": 4.8e-05,
      "loss": 0.0484,
      "step": 381
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.24885250627994537,
      "learning_rate": 4.76e-05,
      "loss": 0.0553,
      "step": 382
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.2897038161754608,
      "learning_rate": 4.72e-05,
      "loss": 0.0239,
      "step": 383
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.35210248827934265,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.0263,
      "step": 384
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.20036375522613525,
      "learning_rate": 4.64e-05,
      "loss": 0.0242,
      "step": 385
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.23456351459026337,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.0515,
      "step": 386
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.2617875337600708,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.0531,
      "step": 387
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.21218141913414001,
      "learning_rate": 4.52e-05,
      "loss": 0.0194,
      "step": 388
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.3811226785182953,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.0534,
      "step": 389
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.3255692720413208,
      "learning_rate": 4.44e-05,
      "loss": 0.0239,
      "step": 390
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.28065764904022217,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0493,
      "step": 391
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.463149756193161,
      "learning_rate": 4.36e-05,
      "loss": 0.0641,
      "step": 392
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.2691357433795929,
      "learning_rate": 4.32e-05,
      "loss": 0.0219,
      "step": 393
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.43513646721839905,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.0576,
      "step": 394
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.2629465162754059,
      "learning_rate": 4.24e-05,
      "loss": 0.0205,
      "step": 395
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.2929363548755646,
      "learning_rate": 4.2e-05,
      "loss": 0.0208,
      "step": 396
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.8108522295951843,
      "learning_rate": 4.16e-05,
      "loss": 0.0751,
      "step": 397
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.7652090191841125,
      "learning_rate": 4.12e-05,
      "loss": 0.0552,
      "step": 398
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.2738514244556427,
      "learning_rate": 4.08e-05,
      "loss": 0.0521,
      "step": 399
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2761897146701813,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.0561,
      "step": 400
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.3203904926776886,
      "learning_rate": 4e-05,
      "loss": 0.0509,
      "step": 401
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.2353261411190033,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.0515,
      "step": 402
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.2429487705230713,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.0238,
      "step": 403
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.33297568559646606,
      "learning_rate": 3.88e-05,
      "loss": 0.0478,
      "step": 404
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.28589800000190735,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0254,
      "step": 405
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.3257857859134674,
      "learning_rate": 3.8e-05,
      "loss": 0.0529,
      "step": 406
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.23718062043190002,
      "learning_rate": 3.76e-05,
      "loss": 0.051,
      "step": 407
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.3051409125328064,
      "learning_rate": 3.72e-05,
      "loss": 0.0296,
      "step": 408
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.2419089376926422,
      "learning_rate": 3.68e-05,
      "loss": 0.0505,
      "step": 409
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.23500511050224304,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.0507,
      "step": 410
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.2784430980682373,
      "learning_rate": 3.6e-05,
      "loss": 0.0519,
      "step": 411
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.2505253553390503,
      "learning_rate": 3.56e-05,
      "loss": 0.0549,
      "step": 412
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.25625401735305786,
      "learning_rate": 3.52e-05,
      "loss": 0.0504,
      "step": 413
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.3207486867904663,
      "learning_rate": 3.48e-05,
      "loss": 0.0519,
      "step": 414
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.241386279463768,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0477,
      "step": 415
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.28948092460632324,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0522,
      "step": 416
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.20772063732147217,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.026,
      "step": 417
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.3822854459285736,
      "learning_rate": 3.32e-05,
      "loss": 0.0618,
      "step": 418
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.3647984564304352,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.0592,
      "step": 419
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3206358551979065,
      "learning_rate": 3.24e-05,
      "loss": 0.0568,
      "step": 420
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.4347003996372223,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0556,
      "step": 421
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.34569841623306274,
      "learning_rate": 3.16e-05,
      "loss": 0.0247,
      "step": 422
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.2844582498073578,
      "learning_rate": 3.12e-05,
      "loss": 0.0536,
      "step": 423
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.2108965516090393,
      "learning_rate": 3.08e-05,
      "loss": 0.0504,
      "step": 424
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.2862774133682251,
      "learning_rate": 3.04e-05,
      "loss": 0.0483,
      "step": 425
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.9901164174079895,
      "learning_rate": 3e-05,
      "loss": 0.0622,
      "step": 426
    },
    {
      "epoch": 0.854,
      "grad_norm": 0.3043963611125946,
      "learning_rate": 2.96e-05,
      "loss": 0.0547,
      "step": 427
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.42486298084259033,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.0519,
      "step": 428
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.26432135701179504,
      "learning_rate": 2.88e-05,
      "loss": 0.0551,
      "step": 429
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.3818023204803467,
      "learning_rate": 2.84e-05,
      "loss": 0.0264,
      "step": 430
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.32452192902565,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0557,
      "step": 431
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.2156059890985489,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.025,
      "step": 432
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.40418559312820435,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.0291,
      "step": 433
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.29214441776275635,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.0231,
      "step": 434
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.39048847556114197,
      "learning_rate": 2.64e-05,
      "loss": 0.0277,
      "step": 435
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.27729228138923645,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0286,
      "step": 436
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.23221838474273682,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.0475,
      "step": 437
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.2986544072628021,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.0553,
      "step": 438
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.30204781889915466,
      "learning_rate": 2.48e-05,
      "loss": 0.0517,
      "step": 439
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.3758302628993988,
      "learning_rate": 2.44e-05,
      "loss": 0.06,
      "step": 440
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.3455694615840912,
      "learning_rate": 2.4e-05,
      "loss": 0.0523,
      "step": 441
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.16168057918548584,
      "learning_rate": 2.36e-05,
      "loss": 0.049,
      "step": 442
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.20540186762809753,
      "learning_rate": 2.32e-05,
      "loss": 0.0529,
      "step": 443
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.17175953090190887,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0234,
      "step": 444
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.485353946685791,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.0525,
      "step": 445
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.35056769847869873,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.0278,
      "step": 446
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.23696626722812653,
      "learning_rate": 2.16e-05,
      "loss": 0.0205,
      "step": 447
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.2701281011104584,
      "learning_rate": 2.12e-05,
      "loss": 0.0507,
      "step": 448
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.2212660163640976,
      "learning_rate": 2.08e-05,
      "loss": 0.0492,
      "step": 449
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.2788671851158142,
      "learning_rate": 2.04e-05,
      "loss": 0.05,
      "step": 450
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.230121910572052,
      "learning_rate": 2e-05,
      "loss": 0.0555,
      "step": 451
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.22155287861824036,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0497,
      "step": 452
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.30933627486228943,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0541,
      "step": 453
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.28985893726348877,
      "learning_rate": 1.88e-05,
      "loss": 0.0526,
      "step": 454
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.3310905396938324,
      "learning_rate": 1.84e-05,
      "loss": 0.0517,
      "step": 455
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.15924271941184998,
      "learning_rate": 1.8e-05,
      "loss": 0.0444,
      "step": 456
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.26412180066108704,
      "learning_rate": 1.76e-05,
      "loss": 0.0549,
      "step": 457
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.27257704734802246,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.0266,
      "step": 458
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.23308491706848145,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0476,
      "step": 459
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.17410273849964142,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 0.0233,
      "step": 460
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.31665927171707153,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0219,
      "step": 461
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.21961723268032074,
      "learning_rate": 1.56e-05,
      "loss": 0.0495,
      "step": 462
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.36643311381340027,
      "learning_rate": 1.52e-05,
      "loss": 0.0554,
      "step": 463
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.18467830121517181,
      "learning_rate": 1.48e-05,
      "loss": 0.0238,
      "step": 464
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.33134305477142334,
      "learning_rate": 1.44e-05,
      "loss": 0.0519,
      "step": 465
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.4383002817630768,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0293,
      "step": 466
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.20761340856552124,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0504,
      "step": 467
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.31701505184173584,
      "learning_rate": 1.32e-05,
      "loss": 0.0257,
      "step": 468
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.31695815920829773,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.052,
      "step": 469
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.2748192250728607,
      "learning_rate": 1.24e-05,
      "loss": 0.0518,
      "step": 470
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.27998843789100647,
      "learning_rate": 1.2e-05,
      "loss": 0.0491,
      "step": 471
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.2376166433095932,
      "learning_rate": 1.16e-05,
      "loss": 0.0264,
      "step": 472
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.2839241623878479,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0512,
      "step": 473
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.2801147997379303,
      "learning_rate": 1.08e-05,
      "loss": 0.0535,
      "step": 474
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.28556084632873535,
      "learning_rate": 1.04e-05,
      "loss": 0.0509,
      "step": 475
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.2845853865146637,
      "learning_rate": 1e-05,
      "loss": 0.0528,
      "step": 476
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.298991322517395,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0264,
      "step": 477
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.3254086375236511,
      "learning_rate": 9.2e-06,
      "loss": 0.026,
      "step": 478
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.21135035157203674,
      "learning_rate": 8.8e-06,
      "loss": 0.0504,
      "step": 479
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2481601983308792,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0216,
      "step": 480
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.22688837349414825,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0253,
      "step": 481
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.3276328146457672,
      "learning_rate": 7.6e-06,
      "loss": 0.0514,
      "step": 482
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.24792766571044922,
      "learning_rate": 7.2e-06,
      "loss": 0.052,
      "step": 483
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.36494219303131104,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0255,
      "step": 484
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.19051547348499298,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0216,
      "step": 485
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.20612052083015442,
      "learning_rate": 6e-06,
      "loss": 0.0531,
      "step": 486
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.2338583916425705,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0254,
      "step": 487
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.4238172471523285,
      "learning_rate": 5.2e-06,
      "loss": 0.0631,
      "step": 488
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.2378843128681183,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0253,
      "step": 489
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.32786116003990173,
      "learning_rate": 4.4e-06,
      "loss": 0.0543,
      "step": 490
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.22980982065200806,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0525,
      "step": 491
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.2670266032218933,
      "learning_rate": 3.6e-06,
      "loss": 0.0504,
      "step": 492
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.45243480801582336,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0604,
      "step": 493
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.26581311225891113,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0506,
      "step": 494
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.20860904455184937,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0501,
      "step": 495
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.21737977862358093,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0508,
      "step": 496
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.3375852704048157,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0568,
      "step": 497
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.3173535466194153,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.048,
      "step": 498
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.3346368074417114,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0546,
      "step": 499
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.536089301109314,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.0615,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1274894990853120.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
