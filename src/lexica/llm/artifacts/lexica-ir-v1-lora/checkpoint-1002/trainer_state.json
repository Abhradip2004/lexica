{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 200,
  "global_step": 1002,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01996007984031936,
      "grad_norm": 0.7485999464988708,
      "learning_rate": 5.8064516129032266e-05,
      "loss": 1.9344,
      "step": 10
    },
    {
      "epoch": 0.03992015968063872,
      "grad_norm": 0.6396299600601196,
      "learning_rate": 0.00012258064516129034,
      "loss": 1.7883,
      "step": 20
    },
    {
      "epoch": 0.059880239520958084,
      "grad_norm": 1.0447865724563599,
      "learning_rate": 0.0001870967741935484,
      "loss": 1.3428,
      "step": 30
    },
    {
      "epoch": 0.07984031936127745,
      "grad_norm": 1.0444341897964478,
      "learning_rate": 0.0001983522142121524,
      "loss": 0.775,
      "step": 40
    },
    {
      "epoch": 0.0998003992015968,
      "grad_norm": 0.894732654094696,
      "learning_rate": 0.00019629248197734295,
      "loss": 0.4025,
      "step": 50
    },
    {
      "epoch": 0.11976047904191617,
      "grad_norm": 0.7485807538032532,
      "learning_rate": 0.00019423274974253346,
      "loss": 0.2532,
      "step": 60
    },
    {
      "epoch": 0.13972055888223553,
      "grad_norm": 0.47042739391326904,
      "learning_rate": 0.000192173017507724,
      "loss": 0.2129,
      "step": 70
    },
    {
      "epoch": 0.1596806387225549,
      "grad_norm": 0.7998100519180298,
      "learning_rate": 0.00019011328527291453,
      "loss": 0.1838,
      "step": 80
    },
    {
      "epoch": 0.17964071856287425,
      "grad_norm": 0.5742449760437012,
      "learning_rate": 0.00018805355303810507,
      "loss": 0.1752,
      "step": 90
    },
    {
      "epoch": 0.1996007984031936,
      "grad_norm": 0.5012485384941101,
      "learning_rate": 0.00018599382080329558,
      "loss": 0.1551,
      "step": 100
    },
    {
      "epoch": 0.21956087824351297,
      "grad_norm": 0.4280073046684265,
      "learning_rate": 0.00018393408856848611,
      "loss": 0.1448,
      "step": 110
    },
    {
      "epoch": 0.23952095808383234,
      "grad_norm": 0.7612729668617249,
      "learning_rate": 0.00018187435633367662,
      "loss": 0.1197,
      "step": 120
    },
    {
      "epoch": 0.25948103792415167,
      "grad_norm": 0.7896780967712402,
      "learning_rate": 0.00017981462409886716,
      "loss": 0.1178,
      "step": 130
    },
    {
      "epoch": 0.27944111776447106,
      "grad_norm": 0.728557288646698,
      "learning_rate": 0.00017775489186405767,
      "loss": 0.1103,
      "step": 140
    },
    {
      "epoch": 0.2994011976047904,
      "grad_norm": 0.5392022728919983,
      "learning_rate": 0.0001756951596292482,
      "loss": 0.0939,
      "step": 150
    },
    {
      "epoch": 0.3193612774451098,
      "grad_norm": 0.9660825729370117,
      "learning_rate": 0.00017363542739443872,
      "loss": 0.0873,
      "step": 160
    },
    {
      "epoch": 0.3393213572854291,
      "grad_norm": 0.8572853803634644,
      "learning_rate": 0.00017157569515962925,
      "loss": 0.0848,
      "step": 170
    },
    {
      "epoch": 0.3592814371257485,
      "grad_norm": 0.8241214752197266,
      "learning_rate": 0.00016951596292481976,
      "loss": 0.0833,
      "step": 180
    },
    {
      "epoch": 0.37924151696606784,
      "grad_norm": 0.44121819734573364,
      "learning_rate": 0.0001674562306900103,
      "loss": 0.0772,
      "step": 190
    },
    {
      "epoch": 0.3992015968063872,
      "grad_norm": 0.399842232465744,
      "learning_rate": 0.00016539649845520083,
      "loss": 0.0727,
      "step": 200
    },
    {
      "epoch": 0.3992015968063872,
      "eval_loss": 0.06831097602844238,
      "eval_runtime": 947.4104,
      "eval_samples_per_second": 0.288,
      "eval_steps_per_second": 0.288,
      "step": 200
    },
    {
      "epoch": 0.41916167664670656,
      "grad_norm": 0.4575192630290985,
      "learning_rate": 0.00016333676622039134,
      "loss": 0.0672,
      "step": 210
    },
    {
      "epoch": 0.43912175648702595,
      "grad_norm": 0.6146311163902283,
      "learning_rate": 0.00016127703398558188,
      "loss": 0.0673,
      "step": 220
    },
    {
      "epoch": 0.4590818363273453,
      "grad_norm": 0.7046932578086853,
      "learning_rate": 0.00015921730175077242,
      "loss": 0.0669,
      "step": 230
    },
    {
      "epoch": 0.47904191616766467,
      "grad_norm": 0.7581400871276855,
      "learning_rate": 0.00015715756951596293,
      "loss": 0.0642,
      "step": 240
    },
    {
      "epoch": 0.499001996007984,
      "grad_norm": 0.507756769657135,
      "learning_rate": 0.00015509783728115346,
      "loss": 0.0578,
      "step": 250
    },
    {
      "epoch": 0.5189620758483033,
      "grad_norm": 0.45209574699401855,
      "learning_rate": 0.000153038105046344,
      "loss": 0.0586,
      "step": 260
    },
    {
      "epoch": 0.5389221556886228,
      "grad_norm": 0.34142351150512695,
      "learning_rate": 0.0001509783728115345,
      "loss": 0.0571,
      "step": 270
    },
    {
      "epoch": 0.5588822355289421,
      "grad_norm": 0.5709838271141052,
      "learning_rate": 0.00014891864057672505,
      "loss": 0.055,
      "step": 280
    },
    {
      "epoch": 0.5788423153692615,
      "grad_norm": 0.3334323465824127,
      "learning_rate": 0.00014685890834191556,
      "loss": 0.0554,
      "step": 290
    },
    {
      "epoch": 0.5988023952095808,
      "grad_norm": 0.4210883378982544,
      "learning_rate": 0.0001447991761071061,
      "loss": 0.0545,
      "step": 300
    },
    {
      "epoch": 0.6187624750499002,
      "grad_norm": 0.30428263545036316,
      "learning_rate": 0.0001427394438722966,
      "loss": 0.053,
      "step": 310
    },
    {
      "epoch": 0.6387225548902196,
      "grad_norm": 0.4047221541404724,
      "learning_rate": 0.00014067971163748714,
      "loss": 0.0513,
      "step": 320
    },
    {
      "epoch": 0.6586826347305389,
      "grad_norm": 0.4828086197376251,
      "learning_rate": 0.00013861997940267765,
      "loss": 0.0523,
      "step": 330
    },
    {
      "epoch": 0.6786427145708582,
      "grad_norm": 0.3016203045845032,
      "learning_rate": 0.00013656024716786818,
      "loss": 0.0559,
      "step": 340
    },
    {
      "epoch": 0.6986027944111777,
      "grad_norm": 0.5159003138542175,
      "learning_rate": 0.00013450051493305872,
      "loss": 0.0529,
      "step": 350
    },
    {
      "epoch": 0.718562874251497,
      "grad_norm": 0.30033841729164124,
      "learning_rate": 0.00013244078269824926,
      "loss": 0.0508,
      "step": 360
    },
    {
      "epoch": 0.7385229540918163,
      "grad_norm": 0.2491530030965805,
      "learning_rate": 0.00013038105046343977,
      "loss": 0.0516,
      "step": 370
    },
    {
      "epoch": 0.7584830339321357,
      "grad_norm": 0.38931843638420105,
      "learning_rate": 0.0001283213182286303,
      "loss": 0.0487,
      "step": 380
    },
    {
      "epoch": 0.7784431137724551,
      "grad_norm": 0.3311496675014496,
      "learning_rate": 0.0001262615859938208,
      "loss": 0.0487,
      "step": 390
    },
    {
      "epoch": 0.7984031936127745,
      "grad_norm": 0.3163582980632782,
      "learning_rate": 0.00012420185375901135,
      "loss": 0.0483,
      "step": 400
    },
    {
      "epoch": 0.7984031936127745,
      "eval_loss": 0.050684716552495956,
      "eval_runtime": 939.6856,
      "eval_samples_per_second": 0.291,
      "eval_steps_per_second": 0.291,
      "step": 400
    },
    {
      "epoch": 0.8183632734530938,
      "grad_norm": 0.3258126974105835,
      "learning_rate": 0.00012214212152420186,
      "loss": 0.047,
      "step": 410
    },
    {
      "epoch": 0.8383233532934131,
      "grad_norm": 0.29253801703453064,
      "learning_rate": 0.0001200823892893924,
      "loss": 0.0482,
      "step": 420
    },
    {
      "epoch": 0.8582834331337326,
      "grad_norm": 0.28154322504997253,
      "learning_rate": 0.0001180226570545829,
      "loss": 0.0495,
      "step": 430
    },
    {
      "epoch": 0.8782435129740519,
      "grad_norm": 0.3316824734210968,
      "learning_rate": 0.00011596292481977344,
      "loss": 0.0505,
      "step": 440
    },
    {
      "epoch": 0.8982035928143712,
      "grad_norm": 0.33441272377967834,
      "learning_rate": 0.00011390319258496396,
      "loss": 0.0536,
      "step": 450
    },
    {
      "epoch": 0.9181636726546906,
      "grad_norm": 0.391439825296402,
      "learning_rate": 0.0001118434603501545,
      "loss": 0.0455,
      "step": 460
    },
    {
      "epoch": 0.93812375249501,
      "grad_norm": 0.31432044506073,
      "learning_rate": 0.00010978372811534501,
      "loss": 0.0477,
      "step": 470
    },
    {
      "epoch": 0.9580838323353293,
      "grad_norm": 0.2975423038005829,
      "learning_rate": 0.00010772399588053555,
      "loss": 0.0499,
      "step": 480
    },
    {
      "epoch": 0.9780439121756487,
      "grad_norm": 0.3018248379230499,
      "learning_rate": 0.00010566426364572606,
      "loss": 0.051,
      "step": 490
    },
    {
      "epoch": 0.998003992015968,
      "grad_norm": 0.30421939492225647,
      "learning_rate": 0.00010360453141091659,
      "loss": 0.0448,
      "step": 500
    },
    {
      "epoch": 1.0179640718562875,
      "grad_norm": 0.2832096517086029,
      "learning_rate": 0.0001015447991761071,
      "loss": 0.0457,
      "step": 510
    },
    {
      "epoch": 1.0379241516966067,
      "grad_norm": 0.26681533455848694,
      "learning_rate": 9.948506694129764e-05,
      "loss": 0.0469,
      "step": 520
    },
    {
      "epoch": 1.0578842315369261,
      "grad_norm": 0.28716766834259033,
      "learning_rate": 9.742533470648816e-05,
      "loss": 0.0498,
      "step": 530
    },
    {
      "epoch": 1.0778443113772456,
      "grad_norm": 0.35163867473602295,
      "learning_rate": 9.536560247167868e-05,
      "loss": 0.0477,
      "step": 540
    },
    {
      "epoch": 1.0978043912175648,
      "grad_norm": 0.2553946375846863,
      "learning_rate": 9.330587023686921e-05,
      "loss": 0.0487,
      "step": 550
    },
    {
      "epoch": 1.1177644710578842,
      "grad_norm": 0.2504488527774811,
      "learning_rate": 9.124613800205973e-05,
      "loss": 0.0463,
      "step": 560
    },
    {
      "epoch": 1.1377245508982037,
      "grad_norm": 0.22696146368980408,
      "learning_rate": 8.918640576725025e-05,
      "loss": 0.0484,
      "step": 570
    },
    {
      "epoch": 1.157684630738523,
      "grad_norm": 0.24873970448970795,
      "learning_rate": 8.712667353244078e-05,
      "loss": 0.0472,
      "step": 580
    },
    {
      "epoch": 1.1776447105788423,
      "grad_norm": 0.27667102217674255,
      "learning_rate": 8.506694129763131e-05,
      "loss": 0.0463,
      "step": 590
    },
    {
      "epoch": 1.1976047904191618,
      "grad_norm": 0.27395644783973694,
      "learning_rate": 8.300720906282184e-05,
      "loss": 0.0455,
      "step": 600
    },
    {
      "epoch": 1.1976047904191618,
      "eval_loss": 0.04786398634314537,
      "eval_runtime": 939.2473,
      "eval_samples_per_second": 0.291,
      "eval_steps_per_second": 0.291,
      "step": 600
    },
    {
      "epoch": 1.217564870259481,
      "grad_norm": 0.2706926167011261,
      "learning_rate": 8.094747682801236e-05,
      "loss": 0.0478,
      "step": 610
    },
    {
      "epoch": 1.2375249500998005,
      "grad_norm": 0.24751470983028412,
      "learning_rate": 7.888774459320288e-05,
      "loss": 0.0495,
      "step": 620
    },
    {
      "epoch": 1.2574850299401197,
      "grad_norm": 0.36099839210510254,
      "learning_rate": 7.68280123583934e-05,
      "loss": 0.0482,
      "step": 630
    },
    {
      "epoch": 1.2774451097804391,
      "grad_norm": 0.2671898603439331,
      "learning_rate": 7.476828012358393e-05,
      "loss": 0.0477,
      "step": 640
    },
    {
      "epoch": 1.2974051896207586,
      "grad_norm": 0.29706695675849915,
      "learning_rate": 7.270854788877447e-05,
      "loss": 0.0438,
      "step": 650
    },
    {
      "epoch": 1.3173652694610778,
      "grad_norm": 0.3306513726711273,
      "learning_rate": 7.064881565396499e-05,
      "loss": 0.0463,
      "step": 660
    },
    {
      "epoch": 1.3373253493013972,
      "grad_norm": 0.2549804151058197,
      "learning_rate": 6.858908341915551e-05,
      "loss": 0.0465,
      "step": 670
    },
    {
      "epoch": 1.3572854291417165,
      "grad_norm": 0.2984159290790558,
      "learning_rate": 6.652935118434603e-05,
      "loss": 0.0503,
      "step": 680
    },
    {
      "epoch": 1.377245508982036,
      "grad_norm": 0.2765977382659912,
      "learning_rate": 6.446961894953656e-05,
      "loss": 0.0451,
      "step": 690
    },
    {
      "epoch": 1.3972055888223553,
      "grad_norm": 0.2811853289604187,
      "learning_rate": 6.240988671472708e-05,
      "loss": 0.0459,
      "step": 700
    },
    {
      "epoch": 1.4171656686626746,
      "grad_norm": 0.24103273451328278,
      "learning_rate": 6.035015447991761e-05,
      "loss": 0.0482,
      "step": 710
    },
    {
      "epoch": 1.437125748502994,
      "grad_norm": 0.24213996529579163,
      "learning_rate": 5.829042224510813e-05,
      "loss": 0.0465,
      "step": 720
    },
    {
      "epoch": 1.4570858283433132,
      "grad_norm": 0.2936404347419739,
      "learning_rate": 5.6230690010298656e-05,
      "loss": 0.0445,
      "step": 730
    },
    {
      "epoch": 1.4770459081836327,
      "grad_norm": 0.3464672267436981,
      "learning_rate": 5.4170957775489186e-05,
      "loss": 0.0457,
      "step": 740
    },
    {
      "epoch": 1.4970059880239521,
      "grad_norm": 0.2663268744945526,
      "learning_rate": 5.211122554067971e-05,
      "loss": 0.0431,
      "step": 750
    },
    {
      "epoch": 1.5169660678642716,
      "grad_norm": 0.25033992528915405,
      "learning_rate": 5.005149330587023e-05,
      "loss": 0.0401,
      "step": 760
    },
    {
      "epoch": 1.5369261477045908,
      "grad_norm": 0.2679786682128906,
      "learning_rate": 4.799176107106076e-05,
      "loss": 0.0453,
      "step": 770
    },
    {
      "epoch": 1.55688622754491,
      "grad_norm": 0.4142603576183319,
      "learning_rate": 4.593202883625129e-05,
      "loss": 0.048,
      "step": 780
    },
    {
      "epoch": 1.5768463073852295,
      "grad_norm": 0.2876633107662201,
      "learning_rate": 4.3872296601441815e-05,
      "loss": 0.0456,
      "step": 790
    },
    {
      "epoch": 1.596806387225549,
      "grad_norm": 0.2598317265510559,
      "learning_rate": 4.181256436663234e-05,
      "loss": 0.0459,
      "step": 800
    },
    {
      "epoch": 1.596806387225549,
      "eval_loss": 0.046792417764663696,
      "eval_runtime": 941.4024,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 800
    },
    {
      "epoch": 1.6167664670658684,
      "grad_norm": 0.30576589703559875,
      "learning_rate": 3.975283213182287e-05,
      "loss": 0.0406,
      "step": 810
    },
    {
      "epoch": 1.6367265469061876,
      "grad_norm": 0.27908599376678467,
      "learning_rate": 3.769309989701339e-05,
      "loss": 0.0435,
      "step": 820
    },
    {
      "epoch": 1.656686626746507,
      "grad_norm": 0.3680528700351715,
      "learning_rate": 3.5633367662203914e-05,
      "loss": 0.0437,
      "step": 830
    },
    {
      "epoch": 1.6766467065868262,
      "grad_norm": 0.2647016644477844,
      "learning_rate": 3.357363542739444e-05,
      "loss": 0.0447,
      "step": 840
    },
    {
      "epoch": 1.6966067864271457,
      "grad_norm": 0.2879142761230469,
      "learning_rate": 3.1513903192584967e-05,
      "loss": 0.0458,
      "step": 850
    },
    {
      "epoch": 1.7165668662674651,
      "grad_norm": 0.24451413750648499,
      "learning_rate": 2.945417095777549e-05,
      "loss": 0.046,
      "step": 860
    },
    {
      "epoch": 1.7365269461077846,
      "grad_norm": 0.266536682844162,
      "learning_rate": 2.7394438722966016e-05,
      "loss": 0.0485,
      "step": 870
    },
    {
      "epoch": 1.7564870259481038,
      "grad_norm": 0.33775344491004944,
      "learning_rate": 2.533470648815654e-05,
      "loss": 0.0461,
      "step": 880
    },
    {
      "epoch": 1.776447105788423,
      "grad_norm": 0.29435303807258606,
      "learning_rate": 2.3274974253347065e-05,
      "loss": 0.0456,
      "step": 890
    },
    {
      "epoch": 1.7964071856287425,
      "grad_norm": 0.30527547001838684,
      "learning_rate": 2.121524201853759e-05,
      "loss": 0.0457,
      "step": 900
    },
    {
      "epoch": 1.816367265469062,
      "grad_norm": 0.31252679228782654,
      "learning_rate": 1.9155509783728115e-05,
      "loss": 0.0451,
      "step": 910
    },
    {
      "epoch": 1.8363273453093814,
      "grad_norm": 0.3234919309616089,
      "learning_rate": 1.709577754891864e-05,
      "loss": 0.0443,
      "step": 920
    },
    {
      "epoch": 1.8562874251497006,
      "grad_norm": 0.27102693915367126,
      "learning_rate": 1.5036045314109168e-05,
      "loss": 0.0456,
      "step": 930
    },
    {
      "epoch": 1.8762475049900198,
      "grad_norm": 0.24593712389469147,
      "learning_rate": 1.2976313079299692e-05,
      "loss": 0.0444,
      "step": 940
    },
    {
      "epoch": 1.8962075848303392,
      "grad_norm": 0.32851138710975647,
      "learning_rate": 1.0916580844490217e-05,
      "loss": 0.0414,
      "step": 950
    },
    {
      "epoch": 1.9161676646706587,
      "grad_norm": 0.38903364539146423,
      "learning_rate": 8.856848609680742e-06,
      "loss": 0.0437,
      "step": 960
    },
    {
      "epoch": 1.9361277445109781,
      "grad_norm": 0.2484056055545807,
      "learning_rate": 6.7971163748712666e-06,
      "loss": 0.0467,
      "step": 970
    },
    {
      "epoch": 1.9560878243512974,
      "grad_norm": 0.2764762043952942,
      "learning_rate": 4.737384140061792e-06,
      "loss": 0.0438,
      "step": 980
    },
    {
      "epoch": 1.9760479041916168,
      "grad_norm": 0.2323971837759018,
      "learning_rate": 2.6776519052523173e-06,
      "loss": 0.0441,
      "step": 990
    },
    {
      "epoch": 1.996007984031936,
      "grad_norm": 0.3002103567123413,
      "learning_rate": 6.179196704428424e-07,
      "loss": 0.0438,
      "step": 1000
    },
    {
      "epoch": 1.996007984031936,
      "eval_loss": 0.045387931168079376,
      "eval_runtime": 940.4131,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1002,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.09648419075072e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
