{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 200,
  "global_step": 2505,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01996007984031936,
      "grad_norm": 0.7482186555862427,
      "learning_rate": 2.368421052631579e-05,
      "loss": 1.9464,
      "step": 10
    },
    {
      "epoch": 0.03992015968063872,
      "grad_norm": 0.8174134492874146,
      "learning_rate": 5e-05,
      "loss": 1.917,
      "step": 20
    },
    {
      "epoch": 0.059880239520958084,
      "grad_norm": 0.6723096370697021,
      "learning_rate": 7.631578947368422e-05,
      "loss": 1.6483,
      "step": 30
    },
    {
      "epoch": 0.07984031936127745,
      "grad_norm": 1.2496390342712402,
      "learning_rate": 0.00010263157894736844,
      "loss": 1.3884,
      "step": 40
    },
    {
      "epoch": 0.0998003992015968,
      "grad_norm": 1.2841870784759521,
      "learning_rate": 0.00012894736842105264,
      "loss": 0.9982,
      "step": 50
    },
    {
      "epoch": 0.11976047904191617,
      "grad_norm": 1.0999908447265625,
      "learning_rate": 0.00015526315789473686,
      "loss": 0.61,
      "step": 60
    },
    {
      "epoch": 0.13972055888223553,
      "grad_norm": 1.2059059143066406,
      "learning_rate": 0.00018157894736842107,
      "loss": 0.359,
      "step": 70
    },
    {
      "epoch": 0.1596806387225549,
      "grad_norm": 0.9008543491363525,
      "learning_rate": 0.000199752984767394,
      "loss": 0.2508,
      "step": 80
    },
    {
      "epoch": 0.17964071856287425,
      "grad_norm": 0.6624686121940613,
      "learning_rate": 0.0001989296006587073,
      "loss": 0.2117,
      "step": 90
    },
    {
      "epoch": 0.1996007984031936,
      "grad_norm": 0.46362030506134033,
      "learning_rate": 0.0001981062165500206,
      "loss": 0.1817,
      "step": 100
    },
    {
      "epoch": 0.21956087824351297,
      "grad_norm": 0.39491167664527893,
      "learning_rate": 0.0001972828324413339,
      "loss": 0.1657,
      "step": 110
    },
    {
      "epoch": 0.23952095808383234,
      "grad_norm": 0.6539045572280884,
      "learning_rate": 0.0001964594483326472,
      "loss": 0.1371,
      "step": 120
    },
    {
      "epoch": 0.25948103792415167,
      "grad_norm": 0.49082738161087036,
      "learning_rate": 0.00019563606422396047,
      "loss": 0.1366,
      "step": 130
    },
    {
      "epoch": 0.27944111776447106,
      "grad_norm": 0.46344906091690063,
      "learning_rate": 0.0001948126801152738,
      "loss": 0.1238,
      "step": 140
    },
    {
      "epoch": 0.2994011976047904,
      "grad_norm": 0.5203375816345215,
      "learning_rate": 0.0001939892960065871,
      "loss": 0.1123,
      "step": 150
    },
    {
      "epoch": 0.3193612774451098,
      "grad_norm": 0.7648354768753052,
      "learning_rate": 0.0001931659118979004,
      "loss": 0.0981,
      "step": 160
    },
    {
      "epoch": 0.3393213572854291,
      "grad_norm": 0.5157313942909241,
      "learning_rate": 0.00019234252778921367,
      "loss": 0.0987,
      "step": 170
    },
    {
      "epoch": 0.3592814371257485,
      "grad_norm": 0.8449365496635437,
      "learning_rate": 0.00019151914368052697,
      "loss": 0.0936,
      "step": 180
    },
    {
      "epoch": 0.37924151696606784,
      "grad_norm": 0.6193696856498718,
      "learning_rate": 0.00019069575957184027,
      "loss": 0.0827,
      "step": 190
    },
    {
      "epoch": 0.3992015968063872,
      "grad_norm": 0.49458593130111694,
      "learning_rate": 0.00018987237546315357,
      "loss": 0.0771,
      "step": 200
    },
    {
      "epoch": 0.3992015968063872,
      "eval_loss": 0.07679469138383865,
      "eval_runtime": 944.3178,
      "eval_samples_per_second": 0.289,
      "eval_steps_per_second": 0.289,
      "step": 200
    },
    {
      "epoch": 0.41916167664670656,
      "grad_norm": 0.5514602661132812,
      "learning_rate": 0.00018904899135446687,
      "loss": 0.0737,
      "step": 210
    },
    {
      "epoch": 0.43912175648702595,
      "grad_norm": 0.5564025640487671,
      "learning_rate": 0.00018822560724578014,
      "loss": 0.0709,
      "step": 220
    },
    {
      "epoch": 0.4590818363273453,
      "grad_norm": 0.553178608417511,
      "learning_rate": 0.00018740222313709347,
      "loss": 0.0701,
      "step": 230
    },
    {
      "epoch": 0.47904191616766467,
      "grad_norm": 0.6611630320549011,
      "learning_rate": 0.00018657883902840677,
      "loss": 0.0669,
      "step": 240
    },
    {
      "epoch": 0.499001996007984,
      "grad_norm": 0.48029348254203796,
      "learning_rate": 0.00018575545491972007,
      "loss": 0.0598,
      "step": 250
    },
    {
      "epoch": 0.5189620758483033,
      "grad_norm": 0.4253677725791931,
      "learning_rate": 0.00018493207081103337,
      "loss": 0.0615,
      "step": 260
    },
    {
      "epoch": 0.5389221556886228,
      "grad_norm": 0.34051376581192017,
      "learning_rate": 0.00018410868670234664,
      "loss": 0.0593,
      "step": 270
    },
    {
      "epoch": 0.5588822355289421,
      "grad_norm": 0.43536439538002014,
      "learning_rate": 0.00018328530259365994,
      "loss": 0.0581,
      "step": 280
    },
    {
      "epoch": 0.5788423153692615,
      "grad_norm": 0.4020536243915558,
      "learning_rate": 0.00018246191848497325,
      "loss": 0.0572,
      "step": 290
    },
    {
      "epoch": 0.5988023952095808,
      "grad_norm": 0.34732693433761597,
      "learning_rate": 0.00018163853437628655,
      "loss": 0.0573,
      "step": 300
    },
    {
      "epoch": 0.6187624750499002,
      "grad_norm": 0.2788216173648834,
      "learning_rate": 0.00018081515026759985,
      "loss": 0.0547,
      "step": 310
    },
    {
      "epoch": 0.6387225548902196,
      "grad_norm": 0.40226492285728455,
      "learning_rate": 0.00017999176615891315,
      "loss": 0.0515,
      "step": 320
    },
    {
      "epoch": 0.6586826347305389,
      "grad_norm": 0.43543845415115356,
      "learning_rate": 0.00017916838205022645,
      "loss": 0.0541,
      "step": 330
    },
    {
      "epoch": 0.6786427145708582,
      "grad_norm": 0.5408825874328613,
      "learning_rate": 0.00017834499794153975,
      "loss": 0.0565,
      "step": 340
    },
    {
      "epoch": 0.6986027944111777,
      "grad_norm": 0.698832094669342,
      "learning_rate": 0.00017752161383285305,
      "loss": 0.0537,
      "step": 350
    },
    {
      "epoch": 0.718562874251497,
      "grad_norm": 0.3245405852794647,
      "learning_rate": 0.00017669822972416635,
      "loss": 0.0517,
      "step": 360
    },
    {
      "epoch": 0.7385229540918163,
      "grad_norm": 0.24900050461292267,
      "learning_rate": 0.00017587484561547962,
      "loss": 0.0535,
      "step": 370
    },
    {
      "epoch": 0.7584830339321357,
      "grad_norm": 0.3081606328487396,
      "learning_rate": 0.00017505146150679292,
      "loss": 0.05,
      "step": 380
    },
    {
      "epoch": 0.7784431137724551,
      "grad_norm": 0.3119129240512848,
      "learning_rate": 0.00017422807739810622,
      "loss": 0.0504,
      "step": 390
    },
    {
      "epoch": 0.7984031936127745,
      "grad_norm": 0.37048378586769104,
      "learning_rate": 0.00017340469328941952,
      "loss": 0.0486,
      "step": 400
    },
    {
      "epoch": 0.7984031936127745,
      "eval_loss": 0.05209531635046005,
      "eval_runtime": 939.7245,
      "eval_samples_per_second": 0.291,
      "eval_steps_per_second": 0.291,
      "step": 400
    },
    {
      "epoch": 0.8183632734530938,
      "grad_norm": 0.544281542301178,
      "learning_rate": 0.00017258130918073282,
      "loss": 0.0473,
      "step": 410
    },
    {
      "epoch": 0.8383233532934131,
      "grad_norm": 0.31425949931144714,
      "learning_rate": 0.00017175792507204612,
      "loss": 0.05,
      "step": 420
    },
    {
      "epoch": 0.8582834331337326,
      "grad_norm": 0.2593945860862732,
      "learning_rate": 0.00017093454096335942,
      "loss": 0.0499,
      "step": 430
    },
    {
      "epoch": 0.8782435129740519,
      "grad_norm": 0.24033713340759277,
      "learning_rate": 0.00017011115685467272,
      "loss": 0.0518,
      "step": 440
    },
    {
      "epoch": 0.8982035928143712,
      "grad_norm": 0.2796555161476135,
      "learning_rate": 0.00016928777274598602,
      "loss": 0.0524,
      "step": 450
    },
    {
      "epoch": 0.9181636726546906,
      "grad_norm": 0.371941477060318,
      "learning_rate": 0.0001684643886372993,
      "loss": 0.0471,
      "step": 460
    },
    {
      "epoch": 0.93812375249501,
      "grad_norm": 0.27760279178619385,
      "learning_rate": 0.0001676410045286126,
      "loss": 0.0481,
      "step": 470
    },
    {
      "epoch": 0.9580838323353293,
      "grad_norm": 0.24202778935432434,
      "learning_rate": 0.0001668176204199259,
      "loss": 0.0508,
      "step": 480
    },
    {
      "epoch": 0.9780439121756487,
      "grad_norm": 0.2727862298488617,
      "learning_rate": 0.0001659942363112392,
      "loss": 0.0522,
      "step": 490
    },
    {
      "epoch": 0.998003992015968,
      "grad_norm": 0.23257054388523102,
      "learning_rate": 0.0001651708522025525,
      "loss": 0.0454,
      "step": 500
    },
    {
      "epoch": 1.0179640718562875,
      "grad_norm": 0.2285352200269699,
      "learning_rate": 0.0001643474680938658,
      "loss": 0.0466,
      "step": 510
    },
    {
      "epoch": 1.0379241516966067,
      "grad_norm": 0.8952529430389404,
      "learning_rate": 0.0001635240839851791,
      "loss": 0.0488,
      "step": 520
    },
    {
      "epoch": 1.0578842315369261,
      "grad_norm": 0.317704975605011,
      "learning_rate": 0.0001627006998764924,
      "loss": 0.0505,
      "step": 530
    },
    {
      "epoch": 1.0778443113772456,
      "grad_norm": 0.4022707939147949,
      "learning_rate": 0.0001618773157678057,
      "loss": 0.0491,
      "step": 540
    },
    {
      "epoch": 1.0978043912175648,
      "grad_norm": 0.2672787010669708,
      "learning_rate": 0.000161053931659119,
      "loss": 0.05,
      "step": 550
    },
    {
      "epoch": 1.1177644710578842,
      "grad_norm": 0.2617451846599579,
      "learning_rate": 0.00016023054755043227,
      "loss": 0.0489,
      "step": 560
    },
    {
      "epoch": 1.1377245508982037,
      "grad_norm": 0.18734318017959595,
      "learning_rate": 0.00015940716344174557,
      "loss": 0.0502,
      "step": 570
    },
    {
      "epoch": 1.157684630738523,
      "grad_norm": 0.21273061633110046,
      "learning_rate": 0.00015858377933305887,
      "loss": 0.0488,
      "step": 580
    },
    {
      "epoch": 1.1776447105788423,
      "grad_norm": 0.2842208445072174,
      "learning_rate": 0.00015776039522437217,
      "loss": 0.0484,
      "step": 590
    },
    {
      "epoch": 1.1976047904191618,
      "grad_norm": 0.20531690120697021,
      "learning_rate": 0.00015693701111568547,
      "loss": 0.0469,
      "step": 600
    },
    {
      "epoch": 1.1976047904191618,
      "eval_loss": 0.048673637211322784,
      "eval_runtime": 939.7557,
      "eval_samples_per_second": 0.291,
      "eval_steps_per_second": 0.291,
      "step": 600
    },
    {
      "epoch": 1.217564870259481,
      "grad_norm": 0.29378047585487366,
      "learning_rate": 0.00015611362700699877,
      "loss": 0.0473,
      "step": 610
    },
    {
      "epoch": 1.2375249500998005,
      "grad_norm": 0.2649632394313812,
      "learning_rate": 0.00015529024289831207,
      "loss": 0.0514,
      "step": 620
    },
    {
      "epoch": 1.2574850299401197,
      "grad_norm": 0.29892802238464355,
      "learning_rate": 0.00015446685878962537,
      "loss": 0.0497,
      "step": 630
    },
    {
      "epoch": 1.2774451097804391,
      "grad_norm": 0.23124386370182037,
      "learning_rate": 0.00015364347468093867,
      "loss": 0.0485,
      "step": 640
    },
    {
      "epoch": 1.2974051896207586,
      "grad_norm": 0.26364514231681824,
      "learning_rate": 0.00015282009057225197,
      "loss": 0.0448,
      "step": 650
    },
    {
      "epoch": 1.3173652694610778,
      "grad_norm": 0.2554469108581543,
      "learning_rate": 0.00015199670646356525,
      "loss": 0.0473,
      "step": 660
    },
    {
      "epoch": 1.3373253493013972,
      "grad_norm": 0.2599729299545288,
      "learning_rate": 0.00015117332235487855,
      "loss": 0.0473,
      "step": 670
    },
    {
      "epoch": 1.3572854291417165,
      "grad_norm": 0.30030202865600586,
      "learning_rate": 0.00015034993824619185,
      "loss": 0.0501,
      "step": 680
    },
    {
      "epoch": 1.377245508982036,
      "grad_norm": 0.7002856731414795,
      "learning_rate": 0.00014952655413750515,
      "loss": 0.046,
      "step": 690
    },
    {
      "epoch": 1.3972055888223553,
      "grad_norm": 0.21561753749847412,
      "learning_rate": 0.00014870317002881847,
      "loss": 0.0465,
      "step": 700
    },
    {
      "epoch": 1.4171656686626746,
      "grad_norm": 0.22397559881210327,
      "learning_rate": 0.00014787978592013175,
      "loss": 0.0494,
      "step": 710
    },
    {
      "epoch": 1.437125748502994,
      "grad_norm": 0.19841518998146057,
      "learning_rate": 0.00014705640181144505,
      "loss": 0.0465,
      "step": 720
    },
    {
      "epoch": 1.4570858283433132,
      "grad_norm": 0.24761725962162018,
      "learning_rate": 0.00014623301770275835,
      "loss": 0.0456,
      "step": 730
    },
    {
      "epoch": 1.4770459081836327,
      "grad_norm": 0.25956103205680847,
      "learning_rate": 0.00014540963359407165,
      "loss": 0.047,
      "step": 740
    },
    {
      "epoch": 1.4970059880239521,
      "grad_norm": 0.25230589509010315,
      "learning_rate": 0.00014458624948538492,
      "loss": 0.0436,
      "step": 750
    },
    {
      "epoch": 1.5169660678642716,
      "grad_norm": 0.22327755391597748,
      "learning_rate": 0.00014376286537669822,
      "loss": 0.0411,
      "step": 760
    },
    {
      "epoch": 1.5369261477045908,
      "grad_norm": 0.2269241362810135,
      "learning_rate": 0.00014293948126801152,
      "loss": 0.0459,
      "step": 770
    },
    {
      "epoch": 1.55688622754491,
      "grad_norm": 0.20222453773021698,
      "learning_rate": 0.00014211609715932482,
      "loss": 0.0484,
      "step": 780
    },
    {
      "epoch": 1.5768463073852295,
      "grad_norm": 0.2591034770011902,
      "learning_rate": 0.00014129271305063815,
      "loss": 0.046,
      "step": 790
    },
    {
      "epoch": 1.596806387225549,
      "grad_norm": 0.2471097856760025,
      "learning_rate": 0.00014046932894195142,
      "loss": 0.0465,
      "step": 800
    },
    {
      "epoch": 1.596806387225549,
      "eval_loss": 0.047447457909584045,
      "eval_runtime": 940.1592,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 800
    },
    {
      "epoch": 1.6167664670658684,
      "grad_norm": 0.21192410588264465,
      "learning_rate": 0.00013964594483326472,
      "loss": 0.0414,
      "step": 810
    },
    {
      "epoch": 1.6367265469061876,
      "grad_norm": 0.20543530583381653,
      "learning_rate": 0.00013882256072457802,
      "loss": 0.044,
      "step": 820
    },
    {
      "epoch": 1.656686626746507,
      "grad_norm": 0.29396939277648926,
      "learning_rate": 0.00013799917661589132,
      "loss": 0.0438,
      "step": 830
    },
    {
      "epoch": 1.6766467065868262,
      "grad_norm": 0.21252687275409698,
      "learning_rate": 0.00013717579250720462,
      "loss": 0.0457,
      "step": 840
    },
    {
      "epoch": 1.6966067864271457,
      "grad_norm": 0.1771775335073471,
      "learning_rate": 0.0001363524083985179,
      "loss": 0.0466,
      "step": 850
    },
    {
      "epoch": 1.7165668662674651,
      "grad_norm": 0.20627708733081818,
      "learning_rate": 0.0001355290242898312,
      "loss": 0.0455,
      "step": 860
    },
    {
      "epoch": 1.7365269461077846,
      "grad_norm": 0.20289373397827148,
      "learning_rate": 0.0001347056401811445,
      "loss": 0.0485,
      "step": 870
    },
    {
      "epoch": 1.7564870259481038,
      "grad_norm": 0.23925015330314636,
      "learning_rate": 0.00013388225607245782,
      "loss": 0.0471,
      "step": 880
    },
    {
      "epoch": 1.776447105788423,
      "grad_norm": 0.2644994854927063,
      "learning_rate": 0.00013305887196377112,
      "loss": 0.0465,
      "step": 890
    },
    {
      "epoch": 1.7964071856287425,
      "grad_norm": 0.265692800283432,
      "learning_rate": 0.0001322354878550844,
      "loss": 0.0457,
      "step": 900
    },
    {
      "epoch": 1.816367265469062,
      "grad_norm": 0.23207849264144897,
      "learning_rate": 0.0001314121037463977,
      "loss": 0.0466,
      "step": 910
    },
    {
      "epoch": 1.8363273453093814,
      "grad_norm": 0.21140716969966888,
      "learning_rate": 0.000130588719637711,
      "loss": 0.0451,
      "step": 920
    },
    {
      "epoch": 1.8562874251497006,
      "grad_norm": 0.17914384603500366,
      "learning_rate": 0.0001297653355290243,
      "loss": 0.0474,
      "step": 930
    },
    {
      "epoch": 1.8762475049900198,
      "grad_norm": 0.20202799141407013,
      "learning_rate": 0.0001289419514203376,
      "loss": 0.0445,
      "step": 940
    },
    {
      "epoch": 1.8962075848303392,
      "grad_norm": 0.19218286871910095,
      "learning_rate": 0.00012811856731165087,
      "loss": 0.042,
      "step": 950
    },
    {
      "epoch": 1.9161676646706587,
      "grad_norm": 0.20729421079158783,
      "learning_rate": 0.00012729518320296417,
      "loss": 0.044,
      "step": 960
    },
    {
      "epoch": 1.9361277445109781,
      "grad_norm": 0.1883518546819687,
      "learning_rate": 0.0001264717990942775,
      "loss": 0.0474,
      "step": 970
    },
    {
      "epoch": 1.9560878243512974,
      "grad_norm": 0.24669870734214783,
      "learning_rate": 0.0001256484149855908,
      "loss": 0.0439,
      "step": 980
    },
    {
      "epoch": 1.9760479041916168,
      "grad_norm": 0.2103998214006424,
      "learning_rate": 0.0001248250308769041,
      "loss": 0.0442,
      "step": 990
    },
    {
      "epoch": 1.996007984031936,
      "grad_norm": 0.20700766146183014,
      "learning_rate": 0.00012400164676821737,
      "loss": 0.0446,
      "step": 1000
    },
    {
      "epoch": 1.996007984031936,
      "eval_loss": 0.046004194766283035,
      "eval_runtime": 942.2005,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 1000
    },
    {
      "epoch": 2.0159680638722555,
      "grad_norm": 0.2744113504886627,
      "learning_rate": 0.00012317826265953067,
      "loss": 0.0407,
      "step": 1010
    },
    {
      "epoch": 2.035928143712575,
      "grad_norm": 0.20440129935741425,
      "learning_rate": 0.00012235487855084397,
      "loss": 0.044,
      "step": 1020
    },
    {
      "epoch": 2.0558882235528944,
      "grad_norm": 0.2345343679189682,
      "learning_rate": 0.00012153149444215727,
      "loss": 0.0457,
      "step": 1030
    },
    {
      "epoch": 2.0758483033932134,
      "grad_norm": 0.2142736166715622,
      "learning_rate": 0.00012070811033347056,
      "loss": 0.0413,
      "step": 1040
    },
    {
      "epoch": 2.095808383233533,
      "grad_norm": 0.19856086373329163,
      "learning_rate": 0.00011988472622478386,
      "loss": 0.0449,
      "step": 1050
    },
    {
      "epoch": 2.1157684630738522,
      "grad_norm": 0.2340776026248932,
      "learning_rate": 0.00011906134211609716,
      "loss": 0.0443,
      "step": 1060
    },
    {
      "epoch": 2.1357285429141717,
      "grad_norm": 0.3181880712509155,
      "learning_rate": 0.00011823795800741046,
      "loss": 0.042,
      "step": 1070
    },
    {
      "epoch": 2.155688622754491,
      "grad_norm": 0.20686793327331543,
      "learning_rate": 0.00011741457389872376,
      "loss": 0.0435,
      "step": 1080
    },
    {
      "epoch": 2.1756487025948106,
      "grad_norm": 0.1944727748632431,
      "learning_rate": 0.00011659118979003705,
      "loss": 0.043,
      "step": 1090
    },
    {
      "epoch": 2.1956087824351296,
      "grad_norm": 0.20566870272159576,
      "learning_rate": 0.00011576780568135035,
      "loss": 0.043,
      "step": 1100
    },
    {
      "epoch": 2.215568862275449,
      "grad_norm": 0.25031617283821106,
      "learning_rate": 0.00011494442157266365,
      "loss": 0.0422,
      "step": 1110
    },
    {
      "epoch": 2.2355289421157685,
      "grad_norm": 0.20413587987422943,
      "learning_rate": 0.00011412103746397695,
      "loss": 0.0452,
      "step": 1120
    },
    {
      "epoch": 2.255489021956088,
      "grad_norm": 0.25951358675956726,
      "learning_rate": 0.00011329765335529026,
      "loss": 0.0434,
      "step": 1130
    },
    {
      "epoch": 2.2754491017964074,
      "grad_norm": 0.24176904559135437,
      "learning_rate": 0.00011247426924660354,
      "loss": 0.0481,
      "step": 1140
    },
    {
      "epoch": 2.2954091816367264,
      "grad_norm": 0.23803439736366272,
      "learning_rate": 0.00011165088513791684,
      "loss": 0.0428,
      "step": 1150
    },
    {
      "epoch": 2.315369261477046,
      "grad_norm": 0.2549296021461487,
      "learning_rate": 0.00011082750102923014,
      "loss": 0.0447,
      "step": 1160
    },
    {
      "epoch": 2.3353293413173652,
      "grad_norm": 0.21021054685115814,
      "learning_rate": 0.00011000411692054344,
      "loss": 0.0451,
      "step": 1170
    },
    {
      "epoch": 2.3552894211576847,
      "grad_norm": 0.20253773033618927,
      "learning_rate": 0.00010918073281185675,
      "loss": 0.0456,
      "step": 1180
    },
    {
      "epoch": 2.375249500998004,
      "grad_norm": 0.16035565733909607,
      "learning_rate": 0.00010835734870317002,
      "loss": 0.0413,
      "step": 1190
    },
    {
      "epoch": 2.3952095808383236,
      "grad_norm": 0.1627013236284256,
      "learning_rate": 0.00010753396459448332,
      "loss": 0.0442,
      "step": 1200
    },
    {
      "epoch": 2.3952095808383236,
      "eval_loss": 0.045601945370435715,
      "eval_runtime": 939.6768,
      "eval_samples_per_second": 0.291,
      "eval_steps_per_second": 0.291,
      "step": 1200
    },
    {
      "epoch": 2.4151696606786426,
      "grad_norm": 0.18103571236133575,
      "learning_rate": 0.00010671058048579662,
      "loss": 0.0481,
      "step": 1210
    },
    {
      "epoch": 2.435129740518962,
      "grad_norm": 0.24571041762828827,
      "learning_rate": 0.00010588719637710994,
      "loss": 0.0481,
      "step": 1220
    },
    {
      "epoch": 2.4550898203592815,
      "grad_norm": 0.2143310010433197,
      "learning_rate": 0.00010506381226842324,
      "loss": 0.0461,
      "step": 1230
    },
    {
      "epoch": 2.475049900199601,
      "grad_norm": 0.19354936480522156,
      "learning_rate": 0.00010424042815973651,
      "loss": 0.0427,
      "step": 1240
    },
    {
      "epoch": 2.49500998003992,
      "grad_norm": 0.26017558574676514,
      "learning_rate": 0.00010341704405104981,
      "loss": 0.0471,
      "step": 1250
    },
    {
      "epoch": 2.5149700598802394,
      "grad_norm": 0.17724467813968658,
      "learning_rate": 0.00010259365994236311,
      "loss": 0.0446,
      "step": 1260
    },
    {
      "epoch": 2.534930139720559,
      "grad_norm": 0.18747501075267792,
      "learning_rate": 0.00010177027583367643,
      "loss": 0.0448,
      "step": 1270
    },
    {
      "epoch": 2.5548902195608783,
      "grad_norm": 0.183235302567482,
      "learning_rate": 0.00010094689172498973,
      "loss": 0.0461,
      "step": 1280
    },
    {
      "epoch": 2.5748502994011977,
      "grad_norm": 0.18055589497089386,
      "learning_rate": 0.000100123507616303,
      "loss": 0.044,
      "step": 1290
    },
    {
      "epoch": 2.594810379241517,
      "grad_norm": 0.2134970873594284,
      "learning_rate": 9.93001235076163e-05,
      "loss": 0.0427,
      "step": 1300
    },
    {
      "epoch": 2.6147704590818366,
      "grad_norm": 0.18021173775196075,
      "learning_rate": 9.847673939892961e-05,
      "loss": 0.0404,
      "step": 1310
    },
    {
      "epoch": 2.6347305389221556,
      "grad_norm": 0.18555684387683868,
      "learning_rate": 9.76533552902429e-05,
      "loss": 0.0444,
      "step": 1320
    },
    {
      "epoch": 2.654690618762475,
      "grad_norm": 0.21213605999946594,
      "learning_rate": 9.68299711815562e-05,
      "loss": 0.0486,
      "step": 1330
    },
    {
      "epoch": 2.6746506986027945,
      "grad_norm": 0.19620512425899506,
      "learning_rate": 9.60065870728695e-05,
      "loss": 0.044,
      "step": 1340
    },
    {
      "epoch": 2.694610778443114,
      "grad_norm": 0.16280387341976166,
      "learning_rate": 9.51832029641828e-05,
      "loss": 0.0422,
      "step": 1350
    },
    {
      "epoch": 2.714570858283433,
      "grad_norm": 0.22272776067256927,
      "learning_rate": 9.43598188554961e-05,
      "loss": 0.04,
      "step": 1360
    },
    {
      "epoch": 2.7345309381237524,
      "grad_norm": 0.15813587605953217,
      "learning_rate": 9.353643474680939e-05,
      "loss": 0.0457,
      "step": 1370
    },
    {
      "epoch": 2.754491017964072,
      "grad_norm": 0.20002953708171844,
      "learning_rate": 9.271305063812269e-05,
      "loss": 0.0422,
      "step": 1380
    },
    {
      "epoch": 2.7744510978043913,
      "grad_norm": 0.19346179068088531,
      "learning_rate": 9.188966652943599e-05,
      "loss": 0.0453,
      "step": 1390
    },
    {
      "epoch": 2.7944111776447107,
      "grad_norm": 0.1764691323041916,
      "learning_rate": 9.106628242074929e-05,
      "loss": 0.0402,
      "step": 1400
    },
    {
      "epoch": 2.7944111776447107,
      "eval_loss": 0.045012492686510086,
      "eval_runtime": 939.7893,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 1400
    },
    {
      "epoch": 2.81437125748503,
      "grad_norm": 0.22983314096927643,
      "learning_rate": 9.024289831206259e-05,
      "loss": 0.0433,
      "step": 1410
    },
    {
      "epoch": 2.834331337325349,
      "grad_norm": 0.17749500274658203,
      "learning_rate": 8.941951420337588e-05,
      "loss": 0.0444,
      "step": 1420
    },
    {
      "epoch": 2.8542914171656686,
      "grad_norm": 0.19868822395801544,
      "learning_rate": 8.859613009468918e-05,
      "loss": 0.0466,
      "step": 1430
    },
    {
      "epoch": 2.874251497005988,
      "grad_norm": 0.20603163540363312,
      "learning_rate": 8.777274598600248e-05,
      "loss": 0.0418,
      "step": 1440
    },
    {
      "epoch": 2.8942115768463075,
      "grad_norm": 0.21603325009346008,
      "learning_rate": 8.694936187731578e-05,
      "loss": 0.047,
      "step": 1450
    },
    {
      "epoch": 2.9141716566866265,
      "grad_norm": 0.178809255361557,
      "learning_rate": 8.612597776862908e-05,
      "loss": 0.0397,
      "step": 1460
    },
    {
      "epoch": 2.934131736526946,
      "grad_norm": 0.15723006427288055,
      "learning_rate": 8.530259365994236e-05,
      "loss": 0.0438,
      "step": 1470
    },
    {
      "epoch": 2.9540918163672654,
      "grad_norm": 0.25087153911590576,
      "learning_rate": 8.447920955125566e-05,
      "loss": 0.0432,
      "step": 1480
    },
    {
      "epoch": 2.974051896207585,
      "grad_norm": 0.14211615920066833,
      "learning_rate": 8.365582544256896e-05,
      "loss": 0.0421,
      "step": 1490
    },
    {
      "epoch": 2.9940119760479043,
      "grad_norm": 0.2267160713672638,
      "learning_rate": 8.283244133388226e-05,
      "loss": 0.041,
      "step": 1500
    },
    {
      "epoch": 3.0139720558882237,
      "grad_norm": 0.22961744666099548,
      "learning_rate": 8.200905722519556e-05,
      "loss": 0.0423,
      "step": 1510
    },
    {
      "epoch": 3.0339321357285427,
      "grad_norm": 0.23969998955726624,
      "learning_rate": 8.118567311650885e-05,
      "loss": 0.048,
      "step": 1520
    },
    {
      "epoch": 3.053892215568862,
      "grad_norm": 0.22480051219463348,
      "learning_rate": 8.036228900782215e-05,
      "loss": 0.0423,
      "step": 1530
    },
    {
      "epoch": 3.0738522954091816,
      "grad_norm": 0.192482590675354,
      "learning_rate": 7.953890489913545e-05,
      "loss": 0.0402,
      "step": 1540
    },
    {
      "epoch": 3.093812375249501,
      "grad_norm": 0.1949625313282013,
      "learning_rate": 7.871552079044875e-05,
      "loss": 0.045,
      "step": 1550
    },
    {
      "epoch": 3.1137724550898205,
      "grad_norm": 0.14254137873649597,
      "learning_rate": 7.789213668176205e-05,
      "loss": 0.0421,
      "step": 1560
    },
    {
      "epoch": 3.13373253493014,
      "grad_norm": 0.19510884582996368,
      "learning_rate": 7.706875257307534e-05,
      "loss": 0.0436,
      "step": 1570
    },
    {
      "epoch": 3.153692614770459,
      "grad_norm": 0.1879522204399109,
      "learning_rate": 7.624536846438864e-05,
      "loss": 0.0468,
      "step": 1580
    },
    {
      "epoch": 3.1736526946107784,
      "grad_norm": 0.1843421310186386,
      "learning_rate": 7.542198435570194e-05,
      "loss": 0.045,
      "step": 1590
    },
    {
      "epoch": 3.193612774451098,
      "grad_norm": 0.2220333367586136,
      "learning_rate": 7.459860024701524e-05,
      "loss": 0.0422,
      "step": 1600
    },
    {
      "epoch": 3.193612774451098,
      "eval_loss": 0.045059435069561005,
      "eval_runtime": 940.1903,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 1600
    },
    {
      "epoch": 3.2135728542914173,
      "grad_norm": 0.2234785407781601,
      "learning_rate": 7.377521613832853e-05,
      "loss": 0.0407,
      "step": 1610
    },
    {
      "epoch": 3.2335329341317367,
      "grad_norm": 0.20277227461338043,
      "learning_rate": 7.295183202964183e-05,
      "loss": 0.0419,
      "step": 1620
    },
    {
      "epoch": 3.2534930139720557,
      "grad_norm": 0.20907588303089142,
      "learning_rate": 7.212844792095514e-05,
      "loss": 0.0435,
      "step": 1630
    },
    {
      "epoch": 3.273453093812375,
      "grad_norm": 0.22920821607112885,
      "learning_rate": 7.130506381226843e-05,
      "loss": 0.043,
      "step": 1640
    },
    {
      "epoch": 3.2934131736526946,
      "grad_norm": 0.1966279149055481,
      "learning_rate": 7.048167970358173e-05,
      "loss": 0.0402,
      "step": 1650
    },
    {
      "epoch": 3.313373253493014,
      "grad_norm": 0.15996506810188293,
      "learning_rate": 6.965829559489501e-05,
      "loss": 0.0392,
      "step": 1660
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.1920933872461319,
      "learning_rate": 6.883491148620831e-05,
      "loss": 0.0438,
      "step": 1670
    },
    {
      "epoch": 3.3532934131736525,
      "grad_norm": 0.2280527949333191,
      "learning_rate": 6.801152737752163e-05,
      "loss": 0.0419,
      "step": 1680
    },
    {
      "epoch": 3.373253493013972,
      "grad_norm": 0.21693991124629974,
      "learning_rate": 6.718814326883491e-05,
      "loss": 0.0444,
      "step": 1690
    },
    {
      "epoch": 3.3932135728542914,
      "grad_norm": 0.21519991755485535,
      "learning_rate": 6.636475916014821e-05,
      "loss": 0.0479,
      "step": 1700
    },
    {
      "epoch": 3.413173652694611,
      "grad_norm": 0.16476716101169586,
      "learning_rate": 6.55413750514615e-05,
      "loss": 0.0414,
      "step": 1710
    },
    {
      "epoch": 3.4331337325349303,
      "grad_norm": 0.19968058168888092,
      "learning_rate": 6.471799094277481e-05,
      "loss": 0.041,
      "step": 1720
    },
    {
      "epoch": 3.4530938123752497,
      "grad_norm": 0.1624760627746582,
      "learning_rate": 6.38946068340881e-05,
      "loss": 0.0442,
      "step": 1730
    },
    {
      "epoch": 3.4730538922155687,
      "grad_norm": 0.19284862279891968,
      "learning_rate": 6.30712227254014e-05,
      "loss": 0.0436,
      "step": 1740
    },
    {
      "epoch": 3.493013972055888,
      "grad_norm": 0.23565617203712463,
      "learning_rate": 6.22478386167147e-05,
      "loss": 0.044,
      "step": 1750
    },
    {
      "epoch": 3.5129740518962076,
      "grad_norm": 0.1895885169506073,
      "learning_rate": 6.1424454508028e-05,
      "loss": 0.0456,
      "step": 1760
    },
    {
      "epoch": 3.532934131736527,
      "grad_norm": 0.1927105337381363,
      "learning_rate": 6.0601070399341296e-05,
      "loss": 0.042,
      "step": 1770
    },
    {
      "epoch": 3.552894211576846,
      "grad_norm": 0.24443739652633667,
      "learning_rate": 5.977768629065459e-05,
      "loss": 0.0419,
      "step": 1780
    },
    {
      "epoch": 3.5728542914171655,
      "grad_norm": 0.19360767304897308,
      "learning_rate": 5.895430218196789e-05,
      "loss": 0.0436,
      "step": 1790
    },
    {
      "epoch": 3.592814371257485,
      "grad_norm": 0.20705382525920868,
      "learning_rate": 5.8130918073281196e-05,
      "loss": 0.0461,
      "step": 1800
    },
    {
      "epoch": 3.592814371257485,
      "eval_loss": 0.04477813094854355,
      "eval_runtime": 939.8187,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 1800
    },
    {
      "epoch": 3.6127744510978044,
      "grad_norm": 0.22539642453193665,
      "learning_rate": 5.730753396459448e-05,
      "loss": 0.0405,
      "step": 1810
    },
    {
      "epoch": 3.632734530938124,
      "grad_norm": 0.2856128215789795,
      "learning_rate": 5.648414985590778e-05,
      "loss": 0.0408,
      "step": 1820
    },
    {
      "epoch": 3.6526946107784433,
      "grad_norm": 0.1877547949552536,
      "learning_rate": 5.566076574722108e-05,
      "loss": 0.0402,
      "step": 1830
    },
    {
      "epoch": 3.6726546906187627,
      "grad_norm": 0.1945323944091797,
      "learning_rate": 5.483738163853438e-05,
      "loss": 0.0459,
      "step": 1840
    },
    {
      "epoch": 3.6926147704590817,
      "grad_norm": 0.17658892273902893,
      "learning_rate": 5.4013997529847684e-05,
      "loss": 0.0424,
      "step": 1850
    },
    {
      "epoch": 3.712574850299401,
      "grad_norm": 0.17787189781665802,
      "learning_rate": 5.319061342116097e-05,
      "loss": 0.0443,
      "step": 1860
    },
    {
      "epoch": 3.7325349301397206,
      "grad_norm": 0.23075276613235474,
      "learning_rate": 5.236722931247428e-05,
      "loss": 0.043,
      "step": 1870
    },
    {
      "epoch": 3.75249500998004,
      "grad_norm": 0.2323697954416275,
      "learning_rate": 5.1543845203787564e-05,
      "loss": 0.0438,
      "step": 1880
    },
    {
      "epoch": 3.772455089820359,
      "grad_norm": 0.22254127264022827,
      "learning_rate": 5.072046109510087e-05,
      "loss": 0.0377,
      "step": 1890
    },
    {
      "epoch": 3.7924151696606785,
      "grad_norm": 0.16912537813186646,
      "learning_rate": 4.9897076986414165e-05,
      "loss": 0.0417,
      "step": 1900
    },
    {
      "epoch": 3.812375249500998,
      "grad_norm": 0.18021266162395477,
      "learning_rate": 4.9073692877727465e-05,
      "loss": 0.0421,
      "step": 1910
    },
    {
      "epoch": 3.8323353293413174,
      "grad_norm": 0.22377784550189972,
      "learning_rate": 4.825030876904076e-05,
      "loss": 0.0433,
      "step": 1920
    },
    {
      "epoch": 3.852295409181637,
      "grad_norm": 0.21957045793533325,
      "learning_rate": 4.742692466035405e-05,
      "loss": 0.0382,
      "step": 1930
    },
    {
      "epoch": 3.8722554890219563,
      "grad_norm": 0.17314518988132477,
      "learning_rate": 4.660354055166736e-05,
      "loss": 0.0419,
      "step": 1940
    },
    {
      "epoch": 3.8922155688622757,
      "grad_norm": 0.2045130580663681,
      "learning_rate": 4.578015644298065e-05,
      "loss": 0.0406,
      "step": 1950
    },
    {
      "epoch": 3.9121756487025947,
      "grad_norm": 0.20657546818256378,
      "learning_rate": 4.495677233429395e-05,
      "loss": 0.0442,
      "step": 1960
    },
    {
      "epoch": 3.932135728542914,
      "grad_norm": 0.19154417514801025,
      "learning_rate": 4.4133388225607246e-05,
      "loss": 0.0425,
      "step": 1970
    },
    {
      "epoch": 3.9520958083832336,
      "grad_norm": 0.1951918751001358,
      "learning_rate": 4.3310004116920547e-05,
      "loss": 0.0416,
      "step": 1980
    },
    {
      "epoch": 3.972055888223553,
      "grad_norm": 0.21421568095684052,
      "learning_rate": 4.248662000823384e-05,
      "loss": 0.0408,
      "step": 1990
    },
    {
      "epoch": 3.992015968063872,
      "grad_norm": 0.20897549390792847,
      "learning_rate": 4.166323589954714e-05,
      "loss": 0.04,
      "step": 2000
    },
    {
      "epoch": 3.992015968063872,
      "eval_loss": 0.044228360056877136,
      "eval_runtime": 940.1996,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 2000
    },
    {
      "epoch": 4.0119760479041915,
      "grad_norm": 0.1579504758119583,
      "learning_rate": 4.083985179086044e-05,
      "loss": 0.0433,
      "step": 2010
    },
    {
      "epoch": 4.031936127744511,
      "grad_norm": 0.13968099653720856,
      "learning_rate": 4.0016467682173734e-05,
      "loss": 0.0401,
      "step": 2020
    },
    {
      "epoch": 4.05189620758483,
      "grad_norm": 0.22315248847007751,
      "learning_rate": 3.9193083573487034e-05,
      "loss": 0.0414,
      "step": 2030
    },
    {
      "epoch": 4.07185628742515,
      "grad_norm": 0.22880619764328003,
      "learning_rate": 3.836969946480033e-05,
      "loss": 0.0434,
      "step": 2040
    },
    {
      "epoch": 4.091816367265469,
      "grad_norm": 0.1870647519826889,
      "learning_rate": 3.754631535611363e-05,
      "loss": 0.0405,
      "step": 2050
    },
    {
      "epoch": 4.111776447105789,
      "grad_norm": 0.1843281388282776,
      "learning_rate": 3.672293124742693e-05,
      "loss": 0.0411,
      "step": 2060
    },
    {
      "epoch": 4.131736526946108,
      "grad_norm": 0.1727992594242096,
      "learning_rate": 3.589954713874022e-05,
      "loss": 0.0394,
      "step": 2070
    },
    {
      "epoch": 4.151696606786427,
      "grad_norm": 0.2007206231355667,
      "learning_rate": 3.507616303005352e-05,
      "loss": 0.04,
      "step": 2080
    },
    {
      "epoch": 4.171656686626746,
      "grad_norm": 0.23729769885540009,
      "learning_rate": 3.4252778921366815e-05,
      "loss": 0.038,
      "step": 2090
    },
    {
      "epoch": 4.191616766467066,
      "grad_norm": 0.22569793462753296,
      "learning_rate": 3.3429394812680116e-05,
      "loss": 0.0405,
      "step": 2100
    },
    {
      "epoch": 4.211576846307385,
      "grad_norm": 0.21036407351493835,
      "learning_rate": 3.2606010703993416e-05,
      "loss": 0.043,
      "step": 2110
    },
    {
      "epoch": 4.2315369261477045,
      "grad_norm": 0.20826847851276398,
      "learning_rate": 3.1782626595306716e-05,
      "loss": 0.0433,
      "step": 2120
    },
    {
      "epoch": 4.251497005988024,
      "grad_norm": 0.20695452392101288,
      "learning_rate": 3.095924248662001e-05,
      "loss": 0.0469,
      "step": 2130
    },
    {
      "epoch": 4.271457085828343,
      "grad_norm": 0.19700747728347778,
      "learning_rate": 3.0135858377933306e-05,
      "loss": 0.0386,
      "step": 2140
    },
    {
      "epoch": 4.291417165668663,
      "grad_norm": 0.2144620269536972,
      "learning_rate": 2.9312474269246603e-05,
      "loss": 0.0403,
      "step": 2150
    },
    {
      "epoch": 4.311377245508982,
      "grad_norm": 0.20334118604660034,
      "learning_rate": 2.84890901605599e-05,
      "loss": 0.04,
      "step": 2160
    },
    {
      "epoch": 4.331337325349302,
      "grad_norm": 0.20508018136024475,
      "learning_rate": 2.7665706051873204e-05,
      "loss": 0.0398,
      "step": 2170
    },
    {
      "epoch": 4.351297405189621,
      "grad_norm": 0.1693733036518097,
      "learning_rate": 2.68423219431865e-05,
      "loss": 0.0418,
      "step": 2180
    },
    {
      "epoch": 4.37125748502994,
      "grad_norm": 0.17246849834918976,
      "learning_rate": 2.6018937834499794e-05,
      "loss": 0.0416,
      "step": 2190
    },
    {
      "epoch": 4.391217564870259,
      "grad_norm": 0.201166033744812,
      "learning_rate": 2.519555372581309e-05,
      "loss": 0.0364,
      "step": 2200
    },
    {
      "epoch": 4.391217564870259,
      "eval_loss": 0.0441083163022995,
      "eval_runtime": 941.0357,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 2200
    },
    {
      "epoch": 4.411177644710579,
      "grad_norm": 0.22361521422863007,
      "learning_rate": 2.437216961712639e-05,
      "loss": 0.0413,
      "step": 2210
    },
    {
      "epoch": 4.431137724550898,
      "grad_norm": 0.1931856870651245,
      "learning_rate": 2.3548785508439688e-05,
      "loss": 0.0387,
      "step": 2220
    },
    {
      "epoch": 4.4510978043912175,
      "grad_norm": 0.22399947047233582,
      "learning_rate": 2.2725401399752985e-05,
      "loss": 0.0478,
      "step": 2230
    },
    {
      "epoch": 4.471057884231537,
      "grad_norm": 0.20546981692314148,
      "learning_rate": 2.1902017291066285e-05,
      "loss": 0.0451,
      "step": 2240
    },
    {
      "epoch": 4.491017964071856,
      "grad_norm": 0.20304831862449646,
      "learning_rate": 2.1078633182379582e-05,
      "loss": 0.0393,
      "step": 2250
    },
    {
      "epoch": 4.510978043912176,
      "grad_norm": 0.1938505619764328,
      "learning_rate": 2.025524907369288e-05,
      "loss": 0.0447,
      "step": 2260
    },
    {
      "epoch": 4.530938123752495,
      "grad_norm": 0.21555009484291077,
      "learning_rate": 1.9431864965006176e-05,
      "loss": 0.0414,
      "step": 2270
    },
    {
      "epoch": 4.550898203592815,
      "grad_norm": 0.21290461719036102,
      "learning_rate": 1.8608480856319473e-05,
      "loss": 0.0426,
      "step": 2280
    },
    {
      "epoch": 4.570858283433134,
      "grad_norm": 0.20323573052883148,
      "learning_rate": 1.778509674763277e-05,
      "loss": 0.0422,
      "step": 2290
    },
    {
      "epoch": 4.590818363273453,
      "grad_norm": 0.19274874031543732,
      "learning_rate": 1.696171263894607e-05,
      "loss": 0.0432,
      "step": 2300
    },
    {
      "epoch": 4.610778443113772,
      "grad_norm": 0.21362179517745972,
      "learning_rate": 1.6138328530259367e-05,
      "loss": 0.0396,
      "step": 2310
    },
    {
      "epoch": 4.630738522954092,
      "grad_norm": 0.19125507771968842,
      "learning_rate": 1.5314944421572664e-05,
      "loss": 0.0449,
      "step": 2320
    },
    {
      "epoch": 4.650698602794411,
      "grad_norm": 0.22616708278656006,
      "learning_rate": 1.4491560312885962e-05,
      "loss": 0.0426,
      "step": 2330
    },
    {
      "epoch": 4.6706586826347305,
      "grad_norm": 0.2088223248720169,
      "learning_rate": 1.3668176204199259e-05,
      "loss": 0.0378,
      "step": 2340
    },
    {
      "epoch": 4.69061876247505,
      "grad_norm": 0.22850638628005981,
      "learning_rate": 1.2844792095512556e-05,
      "loss": 0.0408,
      "step": 2350
    },
    {
      "epoch": 4.710578842315369,
      "grad_norm": 0.1906966269016266,
      "learning_rate": 1.2021407986825854e-05,
      "loss": 0.0382,
      "step": 2360
    },
    {
      "epoch": 4.730538922155689,
      "grad_norm": 0.18079322576522827,
      "learning_rate": 1.1198023878139153e-05,
      "loss": 0.043,
      "step": 2370
    },
    {
      "epoch": 4.750499001996008,
      "grad_norm": 0.2533574402332306,
      "learning_rate": 1.037463976945245e-05,
      "loss": 0.0437,
      "step": 2380
    },
    {
      "epoch": 4.770459081836328,
      "grad_norm": 0.26382386684417725,
      "learning_rate": 9.551255660765748e-06,
      "loss": 0.0426,
      "step": 2390
    },
    {
      "epoch": 4.790419161676647,
      "grad_norm": 0.1966710388660431,
      "learning_rate": 8.727871552079045e-06,
      "loss": 0.0429,
      "step": 2400
    },
    {
      "epoch": 4.790419161676647,
      "eval_loss": 0.04369766637682915,
      "eval_runtime": 939.7815,
      "eval_samples_per_second": 0.29,
      "eval_steps_per_second": 0.29,
      "step": 2400
    },
    {
      "epoch": 4.810379241516966,
      "grad_norm": 0.19170600175857544,
      "learning_rate": 7.904487443392344e-06,
      "loss": 0.038,
      "step": 2410
    },
    {
      "epoch": 4.830339321357285,
      "grad_norm": 0.19027292728424072,
      "learning_rate": 7.081103334705641e-06,
      "loss": 0.0428,
      "step": 2420
    },
    {
      "epoch": 4.850299401197605,
      "grad_norm": 0.2490643411874771,
      "learning_rate": 6.2577192260189374e-06,
      "loss": 0.0407,
      "step": 2430
    },
    {
      "epoch": 4.870259481037924,
      "grad_norm": 0.21226096153259277,
      "learning_rate": 5.434335117332236e-06,
      "loss": 0.0411,
      "step": 2440
    },
    {
      "epoch": 4.8902195608782435,
      "grad_norm": 0.2284964621067047,
      "learning_rate": 4.610951008645533e-06,
      "loss": 0.0435,
      "step": 2450
    },
    {
      "epoch": 4.910179640718563,
      "grad_norm": 0.18645790219306946,
      "learning_rate": 3.787566899958831e-06,
      "loss": 0.0433,
      "step": 2460
    },
    {
      "epoch": 4.930139720558882,
      "grad_norm": 0.24623370170593262,
      "learning_rate": 2.9641827912721283e-06,
      "loss": 0.0431,
      "step": 2470
    },
    {
      "epoch": 4.950099800399202,
      "grad_norm": 0.1930328607559204,
      "learning_rate": 2.140798682585426e-06,
      "loss": 0.0373,
      "step": 2480
    },
    {
      "epoch": 4.970059880239521,
      "grad_norm": 0.19403453171253204,
      "learning_rate": 1.3174145738987239e-06,
      "loss": 0.0416,
      "step": 2490
    },
    {
      "epoch": 4.99001996007984,
      "grad_norm": 0.18726499378681183,
      "learning_rate": 4.940304652120215e-07,
      "loss": 0.0406,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2505,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7412104768768e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
