{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.996007984031936,
  "eval_steps": 200,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01996007984031936,
      "grad_norm": 0.8242346048355103,
      "learning_rate": 5.8064516129032266e-05,
      "loss": 2.1593,
      "step": 10
    },
    {
      "epoch": 0.03992015968063872,
      "grad_norm": 0.570152759552002,
      "learning_rate": 0.00012258064516129034,
      "loss": 2.0332,
      "step": 20
    },
    {
      "epoch": 0.059880239520958084,
      "grad_norm": 0.795218288898468,
      "learning_rate": 0.0001870967741935484,
      "loss": 1.6949,
      "step": 30
    },
    {
      "epoch": 0.07984031936127745,
      "grad_norm": 1.3784635066986084,
      "learning_rate": 0.0001983522142121524,
      "loss": 1.1165,
      "step": 40
    },
    {
      "epoch": 0.0998003992015968,
      "grad_norm": 0.57050621509552,
      "learning_rate": 0.00019629248197734295,
      "loss": 0.4698,
      "step": 50
    },
    {
      "epoch": 0.11976047904191617,
      "grad_norm": 0.3503076434135437,
      "learning_rate": 0.00019423274974253346,
      "loss": 0.2292,
      "step": 60
    },
    {
      "epoch": 0.13972055888223553,
      "grad_norm": 0.3748786747455597,
      "learning_rate": 0.000192173017507724,
      "loss": 0.1937,
      "step": 70
    },
    {
      "epoch": 0.1596806387225549,
      "grad_norm": 0.3582174777984619,
      "learning_rate": 0.00019011328527291453,
      "loss": 0.1585,
      "step": 80
    },
    {
      "epoch": 0.17964071856287425,
      "grad_norm": 0.3682652413845062,
      "learning_rate": 0.00018805355303810507,
      "loss": 0.1483,
      "step": 90
    },
    {
      "epoch": 0.1996007984031936,
      "grad_norm": 0.2387416809797287,
      "learning_rate": 0.00018599382080329558,
      "loss": 0.1287,
      "step": 100
    },
    {
      "epoch": 0.21956087824351297,
      "grad_norm": 0.2969318926334381,
      "learning_rate": 0.00018393408856848611,
      "loss": 0.1196,
      "step": 110
    },
    {
      "epoch": 0.23952095808383234,
      "grad_norm": 0.4056342840194702,
      "learning_rate": 0.00018187435633367662,
      "loss": 0.0954,
      "step": 120
    },
    {
      "epoch": 0.25948103792415167,
      "grad_norm": 0.3419225215911865,
      "learning_rate": 0.00017981462409886716,
      "loss": 0.0928,
      "step": 130
    },
    {
      "epoch": 0.27944111776447106,
      "grad_norm": 0.5196499228477478,
      "learning_rate": 0.00017775489186405767,
      "loss": 0.0889,
      "step": 140
    },
    {
      "epoch": 0.2994011976047904,
      "grad_norm": 0.3003248870372772,
      "learning_rate": 0.0001756951596292482,
      "loss": 0.0775,
      "step": 150
    },
    {
      "epoch": 0.3193612774451098,
      "grad_norm": 0.43892741203308105,
      "learning_rate": 0.00017363542739443872,
      "loss": 0.0686,
      "step": 160
    },
    {
      "epoch": 0.3393213572854291,
      "grad_norm": 0.3966244161128998,
      "learning_rate": 0.00017157569515962925,
      "loss": 0.0689,
      "step": 170
    },
    {
      "epoch": 0.3592814371257485,
      "grad_norm": 0.6771419048309326,
      "learning_rate": 0.00016951596292481976,
      "loss": 0.0679,
      "step": 180
    },
    {
      "epoch": 0.37924151696606784,
      "grad_norm": 0.5064764618873596,
      "learning_rate": 0.0001674562306900103,
      "loss": 0.0616,
      "step": 190
    },
    {
      "epoch": 0.3992015968063872,
      "grad_norm": 0.3868517279624939,
      "learning_rate": 0.00016539649845520083,
      "loss": 0.0573,
      "step": 200
    },
    {
      "epoch": 0.3992015968063872,
      "eval_loss": 0.05410914123058319,
      "eval_runtime": 1443.5034,
      "eval_samples_per_second": 0.189,
      "eval_steps_per_second": 0.189,
      "step": 200
    },
    {
      "epoch": 0.41916167664670656,
      "grad_norm": 0.2942342460155487,
      "learning_rate": 0.00016333676622039134,
      "loss": 0.0542,
      "step": 210
    },
    {
      "epoch": 0.43912175648702595,
      "grad_norm": 0.39897802472114563,
      "learning_rate": 0.00016127703398558188,
      "loss": 0.0512,
      "step": 220
    },
    {
      "epoch": 0.4590818363273453,
      "grad_norm": 0.4128798842430115,
      "learning_rate": 0.00015921730175077242,
      "loss": 0.0516,
      "step": 230
    },
    {
      "epoch": 0.47904191616766467,
      "grad_norm": 0.3449934124946594,
      "learning_rate": 0.00015715756951596293,
      "loss": 0.0486,
      "step": 240
    },
    {
      "epoch": 0.499001996007984,
      "grad_norm": 0.317989319562912,
      "learning_rate": 0.00015509783728115346,
      "loss": 0.0419,
      "step": 250
    },
    {
      "epoch": 0.5189620758483033,
      "grad_norm": 0.31250327825546265,
      "learning_rate": 0.000153038105046344,
      "loss": 0.0432,
      "step": 260
    },
    {
      "epoch": 0.5389221556886228,
      "grad_norm": 0.28180021047592163,
      "learning_rate": 0.0001509783728115345,
      "loss": 0.0431,
      "step": 270
    },
    {
      "epoch": 0.5588822355289421,
      "grad_norm": 0.36616846919059753,
      "learning_rate": 0.00014891864057672505,
      "loss": 0.0386,
      "step": 280
    },
    {
      "epoch": 0.5788423153692615,
      "grad_norm": 0.3833855092525482,
      "learning_rate": 0.00014685890834191556,
      "loss": 0.0393,
      "step": 290
    },
    {
      "epoch": 0.5988023952095808,
      "grad_norm": 0.27193862199783325,
      "learning_rate": 0.0001447991761071061,
      "loss": 0.0366,
      "step": 300
    },
    {
      "epoch": 0.6187624750499002,
      "grad_norm": 0.19855853915214539,
      "learning_rate": 0.0001427394438722966,
      "loss": 0.0373,
      "step": 310
    },
    {
      "epoch": 0.6387225548902196,
      "grad_norm": 0.2806200683116913,
      "learning_rate": 0.00014067971163748714,
      "loss": 0.0355,
      "step": 320
    },
    {
      "epoch": 0.6586826347305389,
      "grad_norm": 0.2632668614387512,
      "learning_rate": 0.00013861997940267765,
      "loss": 0.0354,
      "step": 330
    },
    {
      "epoch": 0.6786427145708582,
      "grad_norm": 0.23010075092315674,
      "learning_rate": 0.00013656024716786818,
      "loss": 0.039,
      "step": 340
    },
    {
      "epoch": 0.6986027944111777,
      "grad_norm": 0.2379189133644104,
      "learning_rate": 0.00013450051493305872,
      "loss": 0.0346,
      "step": 350
    },
    {
      "epoch": 0.718562874251497,
      "grad_norm": 0.4375927150249481,
      "learning_rate": 0.00013244078269824926,
      "loss": 0.0356,
      "step": 360
    },
    {
      "epoch": 0.7385229540918163,
      "grad_norm": 0.209171861410141,
      "learning_rate": 0.00013038105046343977,
      "loss": 0.0353,
      "step": 370
    },
    {
      "epoch": 0.7584830339321357,
      "grad_norm": 0.3045090138912201,
      "learning_rate": 0.0001283213182286303,
      "loss": 0.034,
      "step": 380
    },
    {
      "epoch": 0.7784431137724551,
      "grad_norm": 0.23754139244556427,
      "learning_rate": 0.0001262615859938208,
      "loss": 0.0339,
      "step": 390
    },
    {
      "epoch": 0.7984031936127745,
      "grad_norm": 0.25997692346572876,
      "learning_rate": 0.00012420185375901135,
      "loss": 0.0334,
      "step": 400
    },
    {
      "epoch": 0.7984031936127745,
      "eval_loss": 0.034356288611888885,
      "eval_runtime": 1443.1466,
      "eval_samples_per_second": 0.189,
      "eval_steps_per_second": 0.189,
      "step": 400
    },
    {
      "epoch": 0.8183632734530938,
      "grad_norm": 0.20613040030002594,
      "learning_rate": 0.00012214212152420186,
      "loss": 0.0336,
      "step": 410
    },
    {
      "epoch": 0.8383233532934131,
      "grad_norm": 0.25879427790641785,
      "learning_rate": 0.0001200823892893924,
      "loss": 0.0327,
      "step": 420
    },
    {
      "epoch": 0.8582834331337326,
      "grad_norm": 0.20204539597034454,
      "learning_rate": 0.0001180226570545829,
      "loss": 0.0336,
      "step": 430
    },
    {
      "epoch": 0.8782435129740519,
      "grad_norm": 0.2527731657028198,
      "learning_rate": 0.00011596292481977344,
      "loss": 0.0339,
      "step": 440
    },
    {
      "epoch": 0.8982035928143712,
      "grad_norm": 0.23734904825687408,
      "learning_rate": 0.00011390319258496396,
      "loss": 0.0352,
      "step": 450
    },
    {
      "epoch": 0.9181636726546906,
      "grad_norm": 0.26997852325439453,
      "learning_rate": 0.0001118434603501545,
      "loss": 0.0317,
      "step": 460
    },
    {
      "epoch": 0.93812375249501,
      "grad_norm": 0.23983797430992126,
      "learning_rate": 0.00010978372811534501,
      "loss": 0.032,
      "step": 470
    },
    {
      "epoch": 0.9580838323353293,
      "grad_norm": 0.20747996866703033,
      "learning_rate": 0.00010772399588053555,
      "loss": 0.033,
      "step": 480
    },
    {
      "epoch": 0.9780439121756487,
      "grad_norm": 0.23682211339473724,
      "learning_rate": 0.00010566426364572606,
      "loss": 0.0342,
      "step": 490
    },
    {
      "epoch": 0.998003992015968,
      "grad_norm": 0.22787542641162872,
      "learning_rate": 0.00010360453141091659,
      "loss": 0.0292,
      "step": 500
    },
    {
      "epoch": 1.0179640718562875,
      "grad_norm": 0.24579215049743652,
      "learning_rate": 0.0001015447991761071,
      "loss": 0.0308,
      "step": 510
    },
    {
      "epoch": 1.0379241516966067,
      "grad_norm": 0.21312706172466278,
      "learning_rate": 9.948506694129764e-05,
      "loss": 0.0325,
      "step": 520
    },
    {
      "epoch": 1.0578842315369261,
      "grad_norm": 0.17994190752506256,
      "learning_rate": 9.742533470648816e-05,
      "loss": 0.0328,
      "step": 530
    },
    {
      "epoch": 1.0778443113772456,
      "grad_norm": 0.283763587474823,
      "learning_rate": 9.536560247167868e-05,
      "loss": 0.0319,
      "step": 540
    },
    {
      "epoch": 1.0978043912175648,
      "grad_norm": 0.23595848679542542,
      "learning_rate": 9.330587023686921e-05,
      "loss": 0.0313,
      "step": 550
    },
    {
      "epoch": 1.1177644710578842,
      "grad_norm": 0.1682565063238144,
      "learning_rate": 9.124613800205973e-05,
      "loss": 0.031,
      "step": 560
    },
    {
      "epoch": 1.1377245508982037,
      "grad_norm": 0.17424653470516205,
      "learning_rate": 8.918640576725025e-05,
      "loss": 0.0326,
      "step": 570
    },
    {
      "epoch": 1.157684630738523,
      "grad_norm": 0.19721448421478271,
      "learning_rate": 8.712667353244078e-05,
      "loss": 0.0316,
      "step": 580
    },
    {
      "epoch": 1.1776447105788423,
      "grad_norm": 0.1860208809375763,
      "learning_rate": 8.506694129763131e-05,
      "loss": 0.0325,
      "step": 590
    },
    {
      "epoch": 1.1976047904191618,
      "grad_norm": 0.16795463860034943,
      "learning_rate": 8.300720906282184e-05,
      "loss": 0.0302,
      "step": 600
    },
    {
      "epoch": 1.1976047904191618,
      "eval_loss": 0.031910572201013565,
      "eval_runtime": 1443.1999,
      "eval_samples_per_second": 0.189,
      "eval_steps_per_second": 0.189,
      "step": 600
    },
    {
      "epoch": 1.217564870259481,
      "grad_norm": 0.22447644174098969,
      "learning_rate": 8.094747682801236e-05,
      "loss": 0.0318,
      "step": 610
    },
    {
      "epoch": 1.2375249500998005,
      "grad_norm": 0.21550264954566956,
      "learning_rate": 7.888774459320288e-05,
      "loss": 0.0321,
      "step": 620
    },
    {
      "epoch": 1.2574850299401197,
      "grad_norm": 0.20328402519226074,
      "learning_rate": 7.68280123583934e-05,
      "loss": 0.0329,
      "step": 630
    },
    {
      "epoch": 1.2774451097804391,
      "grad_norm": 0.18281690776348114,
      "learning_rate": 7.476828012358393e-05,
      "loss": 0.0325,
      "step": 640
    },
    {
      "epoch": 1.2974051896207586,
      "grad_norm": 0.19757355749607086,
      "learning_rate": 7.270854788877447e-05,
      "loss": 0.0309,
      "step": 650
    },
    {
      "epoch": 1.3173652694610778,
      "grad_norm": 0.23953068256378174,
      "learning_rate": 7.064881565396499e-05,
      "loss": 0.0315,
      "step": 660
    },
    {
      "epoch": 1.3373253493013972,
      "grad_norm": 0.21103231608867645,
      "learning_rate": 6.858908341915551e-05,
      "loss": 0.0317,
      "step": 670
    },
    {
      "epoch": 1.3572854291417165,
      "grad_norm": 0.21521009504795074,
      "learning_rate": 6.652935118434603e-05,
      "loss": 0.0333,
      "step": 680
    },
    {
      "epoch": 1.377245508982036,
      "grad_norm": 0.17729710042476654,
      "learning_rate": 6.446961894953656e-05,
      "loss": 0.0301,
      "step": 690
    },
    {
      "epoch": 1.3972055888223553,
      "grad_norm": 0.1752089560031891,
      "learning_rate": 6.240988671472708e-05,
      "loss": 0.0312,
      "step": 700
    },
    {
      "epoch": 1.4171656686626746,
      "grad_norm": 0.17940203845500946,
      "learning_rate": 6.035015447991761e-05,
      "loss": 0.0321,
      "step": 710
    },
    {
      "epoch": 1.437125748502994,
      "grad_norm": 0.21624210476875305,
      "learning_rate": 5.829042224510813e-05,
      "loss": 0.0308,
      "step": 720
    },
    {
      "epoch": 1.4570858283433132,
      "grad_norm": 0.18912620842456818,
      "learning_rate": 5.6230690010298656e-05,
      "loss": 0.0311,
      "step": 730
    },
    {
      "epoch": 1.4770459081836327,
      "grad_norm": 0.2375892996788025,
      "learning_rate": 5.4170957775489186e-05,
      "loss": 0.0304,
      "step": 740
    },
    {
      "epoch": 1.4970059880239521,
      "grad_norm": 0.1790401190519333,
      "learning_rate": 5.211122554067971e-05,
      "loss": 0.0285,
      "step": 750
    },
    {
      "epoch": 1.5169660678642716,
      "grad_norm": 0.18736964464187622,
      "learning_rate": 5.005149330587023e-05,
      "loss": 0.0283,
      "step": 760
    },
    {
      "epoch": 1.5369261477045908,
      "grad_norm": 0.20914754271507263,
      "learning_rate": 4.799176107106076e-05,
      "loss": 0.0304,
      "step": 770
    },
    {
      "epoch": 1.55688622754491,
      "grad_norm": 0.18296732008457184,
      "learning_rate": 4.593202883625129e-05,
      "loss": 0.0315,
      "step": 780
    },
    {
      "epoch": 1.5768463073852295,
      "grad_norm": 0.2775034010410309,
      "learning_rate": 4.3872296601441815e-05,
      "loss": 0.0308,
      "step": 790
    },
    {
      "epoch": 1.596806387225549,
      "grad_norm": 0.2237938940525055,
      "learning_rate": 4.181256436663234e-05,
      "loss": 0.0304,
      "step": 800
    },
    {
      "epoch": 1.596806387225549,
      "eval_loss": 0.031155450269579887,
      "eval_runtime": 1446.7718,
      "eval_samples_per_second": 0.189,
      "eval_steps_per_second": 0.189,
      "step": 800
    },
    {
      "epoch": 1.6167664670658684,
      "grad_norm": 0.21962730586528778,
      "learning_rate": 3.975283213182287e-05,
      "loss": 0.0279,
      "step": 810
    },
    {
      "epoch": 1.6367265469061876,
      "grad_norm": 0.17513705790042877,
      "learning_rate": 3.769309989701339e-05,
      "loss": 0.0281,
      "step": 820
    },
    {
      "epoch": 1.656686626746507,
      "grad_norm": 0.22835874557495117,
      "learning_rate": 3.5633367662203914e-05,
      "loss": 0.0298,
      "step": 830
    },
    {
      "epoch": 1.6766467065868262,
      "grad_norm": 0.20034828782081604,
      "learning_rate": 3.357363542739444e-05,
      "loss": 0.0304,
      "step": 840
    },
    {
      "epoch": 1.6966067864271457,
      "grad_norm": 0.18739357590675354,
      "learning_rate": 3.1513903192584967e-05,
      "loss": 0.0309,
      "step": 850
    },
    {
      "epoch": 1.7165668662674651,
      "grad_norm": 0.20174266397953033,
      "learning_rate": 2.945417095777549e-05,
      "loss": 0.0297,
      "step": 860
    },
    {
      "epoch": 1.7365269461077846,
      "grad_norm": 0.2221505045890808,
      "learning_rate": 2.7394438722966016e-05,
      "loss": 0.0331,
      "step": 870
    },
    {
      "epoch": 1.7564870259481038,
      "grad_norm": 0.2328069806098938,
      "learning_rate": 2.533470648815654e-05,
      "loss": 0.031,
      "step": 880
    },
    {
      "epoch": 1.776447105788423,
      "grad_norm": 0.21722403168678284,
      "learning_rate": 2.3274974253347065e-05,
      "loss": 0.031,
      "step": 890
    },
    {
      "epoch": 1.7964071856287425,
      "grad_norm": 0.23188048601150513,
      "learning_rate": 2.121524201853759e-05,
      "loss": 0.03,
      "step": 900
    },
    {
      "epoch": 1.816367265469062,
      "grad_norm": 0.26509371399879456,
      "learning_rate": 1.9155509783728115e-05,
      "loss": 0.0297,
      "step": 910
    },
    {
      "epoch": 1.8363273453093814,
      "grad_norm": 0.23531317710876465,
      "learning_rate": 1.709577754891864e-05,
      "loss": 0.0297,
      "step": 920
    },
    {
      "epoch": 1.8562874251497006,
      "grad_norm": 0.20417200028896332,
      "learning_rate": 1.5036045314109168e-05,
      "loss": 0.0306,
      "step": 930
    },
    {
      "epoch": 1.8762475049900198,
      "grad_norm": 0.1926036924123764,
      "learning_rate": 1.2976313079299692e-05,
      "loss": 0.0307,
      "step": 940
    },
    {
      "epoch": 1.8962075848303392,
      "grad_norm": 0.20048049092292786,
      "learning_rate": 1.0916580844490217e-05,
      "loss": 0.0281,
      "step": 950
    },
    {
      "epoch": 1.9161676646706587,
      "grad_norm": 0.21479834616184235,
      "learning_rate": 8.856848609680742e-06,
      "loss": 0.0293,
      "step": 960
    },
    {
      "epoch": 1.9361277445109781,
      "grad_norm": 0.2030642330646515,
      "learning_rate": 6.7971163748712666e-06,
      "loss": 0.0307,
      "step": 970
    },
    {
      "epoch": 1.9560878243512974,
      "grad_norm": 0.22981654107570648,
      "learning_rate": 4.737384140061792e-06,
      "loss": 0.029,
      "step": 980
    },
    {
      "epoch": 1.9760479041916168,
      "grad_norm": 0.17315109074115753,
      "learning_rate": 2.6776519052523173e-06,
      "loss": 0.0293,
      "step": 990
    },
    {
      "epoch": 1.996007984031936,
      "grad_norm": 0.20702899992465973,
      "learning_rate": 6.179196704428424e-07,
      "loss": 0.0294,
      "step": 1000
    },
    {
      "epoch": 1.996007984031936,
      "eval_loss": 0.029891226440668106,
      "eval_runtime": 1446.6366,
      "eval_samples_per_second": 0.189,
      "eval_steps_per_second": 0.189,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 1002,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.639127864683008e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
